import os
import pandas as pd
import json
from pathlib import Path
from typing import Dict, List, Tuple, Set, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging
from datetime import datetime
import time
import traceback
import re
from tqdm import tqdm
from collections import defaultdict
import hashlib

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/root/workspace/sliced_video_annotation.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class SlicedVideoAnnotationProcessor:
    def __init__(self, slice_info_csv: str, slice_video_dir: str, output_base_dir: str):
        """
        åˆå§‹åŒ–åˆ‡ç‰‡è§†é¢‘æ ‡æ³¨å¤„ç†å™¨
        
        å‚æ•°:
            slice_info_csv: åˆ‡ç‰‡ä¿¡æ¯CSVæ–‡ä»¶è·¯å¾„
            slice_video_dir: åˆ‡ç‰‡è§†é¢‘ç›®å½•è·¯å¾„
            output_base_dir: è¾“å‡ºç›®å½•è·¯å¾„
        """
        self.slice_info_csv = slice_info_csv
        self.slice_video_dir = slice_video_dir
        self.output_base_dir = output_base_dir
        self.annotations = {}  # æŒ‰ç±»åˆ«å­˜å‚¨æ ‡æ³¨
        self.processed_annotations = set()  # è®°å½•å·²å¤„ç†çš„æ ‡æ³¨
        self.slice_mapping = {}  # è®°å½•slice_keyåˆ°æœ¬åœ°åˆ‡ç‰‡è§†é¢‘è·¯å¾„çš„æ˜ å°„
        self.slice_stats = {}  # åˆ‡ç‰‡ç»Ÿè®¡ä¿¡æ¯
        
    def load_slice_info(self) -> pd.DataFrame:
        """åŠ è½½åˆ‡ç‰‡ä¿¡æ¯CSVæ–‡ä»¶"""
        try:
            if not os.path.exists(self.slice_info_csv):
                logger.error(f"åˆ‡ç‰‡ä¿¡æ¯CSVæ–‡ä»¶ä¸å­˜åœ¨: {self.slice_info_csv}")
                return pd.DataFrame()
            
            df = pd.read_csv(self.slice_info_csv)
            logger.info(f"åˆ‡ç‰‡ä¿¡æ¯CSVåŠ è½½æˆåŠŸ: {len(df)} è¡Œ")
            
            # éªŒè¯å¿…è¦çš„åˆ—
            required_columns = ['slice_key', 'clipè§†é¢‘è·¯å¾„', 'æ ‡ç­¾', 'T_start', 'T_end', 
                               'seg_start', 'seg_end', 't_start_new', 't_end_new', 'local_slice_path']
            missing_cols = [col for col in required_columns if col not in df.columns]
            
            if missing_cols:
                logger.error(f"åˆ‡ç‰‡ä¿¡æ¯CSVç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
                return pd.DataFrame()
            
            # æ¸…ç†æ•°æ®
            if 'clipè§†é¢‘è·¯å¾„' in df.columns:
                df['clipè§†é¢‘è·¯å¾„'] = df['clipè§†é¢‘è·¯å¾„'].astype(str).str.strip()
            
            if 'æ ‡ç­¾' in df.columns:
                df['æ ‡ç­¾'] = df['æ ‡ç­¾'].astype(str).str.strip()
            
            if 'local_slice_path' in df.columns:
                df['local_slice_path'] = df['local_slice_path'].astype(str).str.strip()
            
            return df
            
        except Exception as e:
            logger.error(f"åŠ è½½åˆ‡ç‰‡ä¿¡æ¯CSVå¤±è´¥: {str(e)}")
            logger.error(traceback.format_exc())
            return pd.DataFrame()
    
    def _create_safe_filename(self, text: str) -> str:
        """åˆ›å»ºå®‰å…¨çš„æ–‡ä»¶å"""
        # æ›¿æ¢éæ³•å­—ç¬¦
        safe = re.sub(r'[<>:"/\\|?*]', '_', text)
        safe = re.sub(r'\s+', '_', safe)
        safe = safe.strip('._')
        
        # é™åˆ¶é•¿åº¦
        if len(safe) > 100:
            safe = safe[:100]
        
        return safe
    
    def _create_annotation_id(self, slice_key: str, idx: int) -> str:
        """åˆ›å»ºæ ‡æ³¨ID"""
        # ä½¿ç”¨slice_keyåˆ›å»ºå“ˆå¸Œ
        hash_input = f"{slice_key}_{idx}".encode('utf-8')
        hash_str = hashlib.md5(hash_input).hexdigest()[:8]
        
        # æå–æ—¶é—´ä¿¡æ¯
        time_match = re.search(r"(\d+)_(\d+)$", slice_key)
        if time_match:
            seg_start, seg_end = time_match.groups()
            time_str = f"{seg_start}s_{seg_end}s"
        else:
            time_str = "unknown"
        
        # ä»slice_keyä¸­æå–æ—¥æœŸä¿¡æ¯
        date_match = re.search(r"(\d{4}-\d{2}-\d{2}_\d{2}-\d{2}-\d{2})", slice_key)
        date_str = date_match.group(1) if date_match else "unknown"
        
        # åˆ›å»ºID
        annotation_id = f"slice_{idx:04d}_{date_str}_{time_str}_{hash_str}"
        return annotation_id
    
    def verify_slice_video_exists(self, local_slice_path: str) -> Tuple[bool, str, int]:
        """éªŒè¯åˆ‡ç‰‡è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨å¹¶è·å–ä¿¡æ¯"""
        if not local_slice_path or pd.isna(local_slice_path):
            return False, "è·¯å¾„ä¸ºç©º", 0
        
        # å°è¯•å‡ ç§å¯èƒ½çš„è·¯å¾„
        possible_paths = [
            local_slice_path,  # åŸå§‹è·¯å¾„
            os.path.join(self.slice_video_dir, local_slice_path),  # ç›¸å¯¹äºåˆ‡ç‰‡ç›®å½•
            os.path.join(self.slice_video_dir, os.path.basename(local_slice_path)),  # åªå–æ–‡ä»¶å
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                try:
                    file_size = os.path.getsize(path)
                    if file_size > 1024:  # è‡³å°‘1KB
                        return True, path, file_size
                except:
                    continue
        
        # å¦‚æœä»¥ä¸Šéƒ½ä¸å­˜åœ¨ï¼Œå°è¯•åœ¨åˆ‡ç‰‡ç›®å½•ä¸­æœç´¢
        try:
            # ä»local_slice_pathä¸­æå–æ–‡ä»¶å
            if os.path.basename(local_slice_path):
                filename = os.path.basename(local_slice_path)
                # åœ¨æ•´ä¸ªåˆ‡ç‰‡ç›®å½•ä¸­æœç´¢
                for root, dirs, files in os.walk(self.slice_video_dir):
                    if filename in files:
                        found_path = os.path.join(root, filename)
                        file_size = os.path.getsize(found_path)
                        return True, found_path, file_size
        except:
            pass
        
        return False, local_slice_path, 0
    
    def process_single_slice(self, row: pd.Series, idx: int) -> Tuple[bool, str]:
        """å¤„ç†å•ä¸ªåˆ‡ç‰‡"""
        try:
            # è·å–å¿…è¦ä¿¡æ¯
            slice_key = str(row['slice_key']).strip()
            label = str(row['æ ‡ç­¾']).strip()
            local_slice_path = str(row.get('local_slice_path', '')).strip()
            
            # è·å–æ—¶é—´ä¿¡æ¯
            t_start_new = float(row.get('t_start_new', 0))
            t_end_new = float(row.get('t_end_new', 0))
            seg_start = float(row.get('seg_start', 0))
            seg_end = float(row.get('seg_end', 0))
            t_start = float(row.get('T_start', 0))
            t_end = float(row.get('T_end', 0))
            
            # éªŒè¯æ•°æ®
            if pd.isna(slice_key) or slice_key == '':
                return False, f"ç¬¬{idx}è¡Œ: slice_keyä¸ºç©º"
            
            if pd.isna(label) or label == '':
                return False, f"ç¬¬{idx}è¡Œ: æ ‡ç­¾ä¸ºç©º"
            
            if pd.isna(local_slice_path) or local_slice_path == '':
                return False, f"ç¬¬{idx}è¡Œ: æœ¬åœ°åˆ‡ç‰‡è·¯å¾„ä¸ºç©º"
            
            # æ£€æŸ¥æ—¶é—´ä¿¡æ¯
            if t_start_new < 0 or t_end_new < 0 or t_start_new >= t_end_new:
                logger.warning(f"ç¬¬{idx}è¡Œ: ç›¸å¯¹æ—¶é—´èŒƒå›´æ— æ•ˆ ({t_start_new}-{t_end_new})")
            
            if seg_end - seg_start != 20:
                logger.warning(f"ç¬¬{idx}è¡Œ: åˆ‡ç‰‡é•¿åº¦ä¸æ˜¯20ç§’ ({seg_start}-{seg_end} = {seg_end-seg_start}s)")
            
            # éªŒè¯åˆ‡ç‰‡è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            video_exists, verified_path, file_size = self.verify_slice_video_exists(local_slice_path)
            
            if not video_exists:
                logger.warning(f"ç¬¬{idx}è¡Œ: åˆ‡ç‰‡è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {local_slice_path}")
                logger.warning(f"  å°è¯•çš„è·¯å¾„: {verified_path}")
                # ä¸è¿”å›å¤±è´¥ï¼Œä½†è®°å½•è­¦å‘Š
            
            # ç”Ÿæˆæ ‡æ³¨ID
            annotation_id = self._create_annotation_id(slice_key, idx)
            
            # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡
            if annotation_id in self.processed_annotations:
                logger.debug(f"è·³è¿‡å·²å¤„ç†çš„æ ‡æ³¨: {annotation_id}")
                return True, f"å·²å¤„ç†: {annotation_id}"
            
            # åˆ›å»ºå®‰å…¨çš„ç±»åˆ«åç§°
            safe_label = self._create_safe_filename(label)
            
            # æ·»åŠ åˆ°æ ‡æ³¨
            if safe_label not in self.annotations:
                self.annotations[safe_label] = []
            
            # æ„å»ºå®Œæ•´çš„æ ‡æ³¨ä¿¡æ¯
            annotation = {
                "id": annotation_id,
                "slice_key": slice_key,
                "slice_video_path": verified_path if video_exists else local_slice_path,
                "label": label,
                "time_range_original": [float(t_start), float(t_end)],  # åŸå§‹è§†é¢‘ä¸­çš„æ—¶é—´
                "time_range_in_slice": [float(t_start_new), float(t_end_new)],  # åˆ‡ç‰‡è§†é¢‘ä¸­çš„ç›¸å¯¹æ—¶é—´
                "slice_window": [float(seg_start), float(seg_end)],  # åˆ‡ç‰‡åœ¨åŸå§‹è§†é¢‘ä¸­çš„æ—¶é—´çª—å£
                "duration_original": float(t_end - t_start),  # åŸå§‹æ—¶é•¿
                "duration_in_slice": float(t_end_new - t_start_new),  # åˆ‡ç‰‡ä¸­çš„æ—¶é•¿
                "source_row": idx,
                "video_exists": video_exists,
                "file_size": file_size,
                "clip_path": str(row.get('clipè§†é¢‘è·¯å¾„', '')).strip(),
                "original_bos_path": f"{row.get('clipè§†é¢‘è·¯å¾„', '').strip()}video.mp4",
                "slice_filename": os.path.basename(verified_path if video_exists else local_slice_path)
            }
            
            self.annotations[safe_label].append(annotation)
            self.processed_annotations.add(annotation_id)
            
            # è®°å½•æ˜ å°„
            self.slice_mapping[slice_key] = {
                "local_path": verified_path if video_exists else local_slice_path,
                "exists": video_exists,
                "file_size": file_size
            }
            
            return True, f"æˆåŠŸæ·»åŠ åˆ‡ç‰‡æ ‡æ³¨: {annotation_id}"
                
        except Exception as e:
            logger.error(f"å¤„ç†åˆ‡ç‰‡ {idx} å¤±è´¥: {str(e)}")
            logger.error(traceback.format_exc())
            return False, f"å¼‚å¸¸: {str(e)}"
    
    def analyze_slice_statistics(self, df: pd.DataFrame) -> Dict:
        """åˆ†æåˆ‡ç‰‡æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "total_slices": len(df),
            "valid_slices": 0,
            "invalid_slices": 0,
            "invalid_reasons": defaultdict(int),
            "unique_labels": [],
            "labels_count": {},
            "video_existence": {"exists": 0, "not_exists": 0, "details": []},
            "time_stats": {
                "slice_lengths": [],
                "action_in_slice_durations": [],
                "avg_action_duration": 0,
                "min_action_duration": float('inf'),
                "max_action_duration": 0
            },
            "file_stats": {
                "total_size_mb": 0,
                "avg_size_mb": 0
            }
        }
        
        for idx, row in df.iterrows():
            try:
                slice_key = str(row['slice_key']).strip()
                label = str(row['æ ‡ç­¾']).strip()
                local_slice_path = str(row.get('local_slice_path', '')).strip()
                
                # æ£€æŸ¥å¿…è¦å­—æ®µ
                if pd.isna(slice_key) or slice_key == '':
                    stats["invalid_slices"] += 1
                    stats["invalid_reasons"]["ç©ºslice_key"] += 1
                    continue
                
                if pd.isna(label) or label == '':
                    stats["invalid_slices"] += 1
                    stats["invalid_reasons"]["ç©ºæ ‡ç­¾"] += 1
                    continue
                
                if pd.isna(local_slice_path) or local_slice_path == '':
                    stats["invalid_slices"] += 1
                    stats["invalid_reasons"]["ç©ºæœ¬åœ°è·¯å¾„"] += 1
                    continue
                
                # æœ‰æ•ˆçš„åˆ‡ç‰‡
                stats["valid_slices"] += 1
                
                # ç»Ÿè®¡æ ‡ç­¾
                if label not in stats["unique_labels"]:
                    stats["unique_labels"].append(label)
                
                if label in stats["labels_count"]:
                    stats["labels_count"][label] += 1
                else:
                    stats["labels_count"][label] = 1
                
                # æ£€æŸ¥åˆ‡ç‰‡è§†é¢‘æ˜¯å¦å­˜åœ¨
                video_exists, verified_path, file_size = self.verify_slice_video_exists(local_slice_path)
                
                if video_exists:
                    stats["video_existence"]["exists"] += 1
                    stats["file_stats"]["total_size_mb"] += file_size / (1024 * 1024)
                else:
                    stats["video_existence"]["not_exists"] += 1
                
                stats["video_existence"]["details"].append({
                    "row": idx,
                    "slice_key": slice_key,
                    "original_path": local_slice_path,
                    "verified_path": verified_path,
                    "exists": video_exists,
                    "label": label,
                    "file_size_mb": file_size / (1024 * 1024) if video_exists else 0
                })
                
                # ç»Ÿè®¡æ—¶é—´ä¿¡æ¯
                seg_start = float(row.get('seg_start', 0))
                seg_end = float(row.get('seg_end', 0))
                t_start_new = float(row.get('t_start_new', 0))
                t_end_new = float(row.get('t_end_new', 0))
                
                slice_length = seg_end - seg_start
                action_duration = t_end_new - t_start_new
                
                stats["time_stats"]["slice_lengths"].append(slice_length)
                stats["time_stats"]["action_in_slice_durations"].append(action_duration)
                stats["time_stats"]["min_action_duration"] = min(
                    stats["time_stats"]["min_action_duration"], action_duration
                )
                stats["time_stats"]["max_action_duration"] = max(
                    stats["time_stats"]["max_action_duration"], action_duration
                )
                        
            except Exception as e:
                logger.debug(f"åˆ†æåˆ‡ç‰‡ {idx} å¤±è´¥: {str(e)}")
                stats["invalid_slices"] += 1
                stats["invalid_reasons"][str(type(e).__name__)] += 1
                continue
        
        # è®¡ç®—ç»Ÿè®¡é‡
        stats["unique_labels_count"] = len(stats["unique_labels"])
        
        if stats["valid_slices"] > 0:
            stats["time_stats"]["avg_action_duration"] = sum(
                stats["time_stats"]["action_in_slice_durations"]
            ) / stats["valid_slices"]
            
            if stats["video_existence"]["exists"] > 0:
                stats["file_stats"]["avg_size_mb"] = stats["file_stats"]["total_size_mb"] / stats["video_existence"]["exists"]
        
        return stats
    
    def save_annotations(self):
        """ä¿å­˜åˆ‡ç‰‡è§†é¢‘æ ‡æ³¨åˆ°JSONæ–‡ä»¶"""
        output_dir = os.path.join(self.output_base_dir, "sliced_annotations")
        os.makedirs(output_dir, exist_ok=True)
        
        total_annotations = 0
        category_stats = {}
        
        # ä¸ºæ¯ä¸ªç±»åˆ«ä¿å­˜å•ç‹¬çš„JSONæ–‡ä»¶
        for label, annotations in self.annotations.items():
            if not annotations:
                continue
                
            # åˆ›å»ºå®‰å…¨æ–‡ä»¶å
            safe_label_name = self._create_safe_filename(label)
            json_path = os.path.join(output_dir, f"{safe_label_name}.json")
            
            # ä¸ºæ¯ä¸ªæ ‡æ³¨æ·»åŠ ç´¢å¼•
            for i, anno in enumerate(annotations):
                anno["index_in_category"] = i
            
            # ä¿å­˜ä¸ºJSON
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(annotations, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ä¿å­˜åˆ‡ç‰‡æ ‡æ³¨æ–‡ä»¶: {json_path} ({len(annotations)} ä¸ªæ ‡æ³¨)")
            total_annotations += len(annotations)
            category_stats[label] = len(annotations)
        
        # ä¿å­˜æ±‡æ€»æ–‡ä»¶
        summary = {
            "total_categories": len(self.annotations),
            "total_annotations": total_annotations,
            "annotations_per_category": category_stats,
            "categories": list(self.annotations.keys()),
            "processing_time": datetime.now().isoformat(),
            "source_csv": self.slice_info_csv,
            "slice_video_dir": self.slice_video_dir
        }
        
        summary_path = os.path.join(output_dir, "summary.json")
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ä¿å­˜åˆ‡ç‰‡æ ‡æ³¨æ±‡æ€»æ–‡ä»¶: {summary_path}")
        
        # ä¿å­˜åˆå¹¶çš„æ‰€æœ‰æ ‡æ³¨
        all_annotations = []
        for label, annotations in self.annotations.items():
            all_annotations.extend(annotations)
        
        all_annotations_path = os.path.join(output_dir, "all_sliced_annotations.json")
        with open(all_annotations_path, 'w', encoding='utf-8') as f:
            json.dump(all_annotations, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ä¿å­˜åˆå¹¶åˆ‡ç‰‡æ ‡æ³¨æ–‡ä»¶: {all_annotations_path} ({len(all_annotations)} ä¸ªæ ‡æ³¨)")
        
        return total_annotations
    
    def save_slice_mapping(self):
        """ä¿å­˜åˆ‡ç‰‡è§†é¢‘è·¯å¾„æ˜ å°„"""
        mapping_path = os.path.join(self.output_base_dir, "slice_mapping.json")
        
        mapping_data = {
            "total_slices": len(self.slice_mapping),
            "slices_exist": sum(1 for m in self.slice_mapping.values() if m.get("exists", False)),
            "slices_missing": sum(1 for m in self.slice_mapping.values() if not m.get("exists", False)),
            "mappings": [
                {
                    "slice_key": slice_key,
                    "local_path": info["local_path"],
                    "exists": info.get("exists", False),
                    "file_size_mb": info.get("file_size", 0) / (1024 * 1024) if info.get("file_size") else 0
                }
                for slice_key, info in self.slice_mapping.items()
            ],
            "processing_time": datetime.now().isoformat()
        }
        
        with open(mapping_path, 'w', encoding='utf-8') as f:
            json.dump(mapping_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ä¿å­˜åˆ‡ç‰‡è·¯å¾„æ˜ å°„: {mapping_path}")
    
    def save_statistics(self, success_count: int, fail_count: int, 
                       data_stats: Dict, fail_details: List, elapsed_time: float):
        """ä¿å­˜è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "processing_summary": {
                "total_processed": success_count + fail_count,
                "success_count": success_count,
                "fail_count": fail_count,
                "success_rate": success_count / (success_count + fail_count) if (success_count + fail_count) > 0 else 0,
                "categories_created": len(self.annotations),
                "annotations_created": sum(len(annos) for annos in self.annotations.values()),
                "processing_time": datetime.now().isoformat(),
                "duration_seconds": elapsed_time
            },
            "data_statistics": data_stats,
            "fail_details": [
                {"row": idx, "reason": reason} for idx, reason in fail_details[:100]
            ],
            "configuration": {
                "slice_info_csv": self.slice_info_csv,
                "slice_video_dir": self.slice_video_dir,
                "output_base_dir": self.output_base_dir
            }
        }
        
        stats_path = os.path.join(self.output_base_dir, "sliced_processing_statistics.json")
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        
        logger.info(f"åˆ‡ç‰‡å¤„ç†ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜: {stats_path}")
        return stats
    
    def process_all(self, max_workers: int = 4):
        """å¤„ç†æ‰€æœ‰åˆ‡ç‰‡æ•°æ®"""
        # åŠ è½½åˆ‡ç‰‡ä¿¡æ¯
        df = self.load_slice_info()
        
        if df.empty:
            logger.error("æ— æ³•åŠ è½½åˆ‡ç‰‡ä¿¡æ¯ï¼Œå¤„ç†ç»ˆæ­¢")
            return 0, 0, {}, []
        
        # åˆ†ææ•°æ®ç»Ÿè®¡
        logger.info("åˆ†æåˆ‡ç‰‡æ•°æ®ç»Ÿè®¡...")
        stats = self.analyze_slice_statistics(df)
        
        print("\n" + "=" * 60)
        print("ğŸ“Š åˆ‡ç‰‡æ ‡æ³¨æ•°æ®ç»Ÿè®¡:")
        print("=" * 60)
        print(f"ğŸ“„ æ€»åˆ‡ç‰‡æ•°: {stats['total_slices']}")
        print(f"âœ… æœ‰æ•ˆåˆ‡ç‰‡: {stats['valid_slices']}")
        print(f"âŒ æ— æ•ˆåˆ‡ç‰‡: {stats['invalid_slices']}")
        
        if stats['invalid_reasons']:
            print(f"ğŸ“‰ æ— æ•ˆåŸå› ç»Ÿè®¡:")
            for reason, count in sorted(stats['invalid_reasons'].items(), key=lambda x: x[1], reverse=True):
                print(f"  - {reason}: {count}")
        
        print(f"ğŸ·ï¸  å”¯ä¸€æ ‡ç­¾ç±»åˆ«: {stats['unique_labels_count']}")
        
        # æ˜¾ç¤ºæ ‡ç­¾ç»Ÿè®¡
        if stats['labels_count']:
            print(f"\nğŸ“‚ æŒ‰ç±»åˆ«ç»Ÿè®¡:")
            sorted_labels = sorted(stats['labels_count'].items(), key=lambda x: x[1], reverse=True)
            for label, count in sorted_labels[:20]:
                print(f"  - {label}: {count} ä¸ªåˆ‡ç‰‡")
            if len(sorted_labels) > 20:
                print(f"  ... è¿˜æœ‰ {len(sorted_labels) - 20} ä¸ªç±»åˆ«")
        
        # æ˜¾ç¤ºæ—¶é—´ç»Ÿè®¡
        print(f"\nâ±ï¸  æ—¶é—´ç»Ÿè®¡:")
        print(f"  - å¹³å‡åŠ¨ä½œæ—¶é•¿: {stats['time_stats']['avg_action_duration']:.2f} ç§’")
        print(f"  - æœ€çŸ­åŠ¨ä½œæ—¶é•¿: {stats['time_stats']['min_action_duration']:.2f} ç§’")
        print(f"  - æœ€é•¿åŠ¨ä½œæ—¶é•¿: {stats['time_stats']['max_action_duration']:.2f} ç§’")
        
        # æ£€æŸ¥åˆ‡ç‰‡é•¿åº¦æ˜¯å¦ä¸º20ç§’
        slice_lengths = stats['time_stats']['slice_lengths']
        if slice_lengths:
            avg_slice_length = sum(slice_lengths) / len(slice_lengths)
            print(f"  - å¹³å‡åˆ‡ç‰‡é•¿åº¦: {avg_slice_length:.2f} ç§’")
            if abs(avg_slice_length - 20) > 0.1:
                print(f"  âš ï¸  è­¦å‘Š: å¹³å‡åˆ‡ç‰‡é•¿åº¦ä¸æ˜¯20ç§’!")
        
        print(f"\nğŸ“¹ åˆ‡ç‰‡è§†é¢‘æ–‡ä»¶æƒ…å†µ:")
        print(f"  âœ… å­˜åœ¨çš„åˆ‡ç‰‡è§†é¢‘: {stats['video_existence']['exists']}")
        print(f"  âŒ ç¼ºå¤±çš„åˆ‡ç‰‡è§†é¢‘: {stats['video_existence']['not_exists']}")
        
        if stats['video_existence']['not_exists'] > 0:
            print(f"\nâš ï¸  è­¦å‘Š: æœ‰ {stats['video_existence']['not_exists']} ä¸ªåˆ‡ç‰‡è§†é¢‘æ–‡ä»¶ç¼ºå¤±!")
            print("å¯èƒ½çš„åŸå› :")
            print("1. åˆ‡ç‰‡è§†é¢‘æœªç”Ÿæˆæˆ–ç”Ÿæˆå¤±è´¥")
            print("2. åˆ‡ç‰‡è§†é¢‘ä¿å­˜è·¯å¾„ä¸CSVä¸­è®°å½•çš„ä¸ä¸€è‡´")
            print("3. è§†é¢‘æ–‡ä»¶è¢«ç§»åŠ¨æˆ–åˆ é™¤")
            
            # æ˜¾ç¤ºä¸åŒ¹é…çš„è¯¦ç»†ä¿¡æ¯
            not_exists_details = [d for d in stats['video_existence']['details'] if not d['exists']]
            if not_exists_details:
                print(f"\nğŸ” ç¼ºå¤±æ–‡ä»¶ç¤ºä¾‹ (å‰3ä¸ª):")
                for i, detail in enumerate(not_exists_details[:3], 1):
                    print(f"\n  {i}. è¡Œ {detail['row']}:")
                    print(f"     æ ‡ç­¾: {detail['label']}")
                    print(f"     slice_key: {detail['slice_key']}")
                    print(f"     åŸå§‹è·¯å¾„: {detail['original_path']}")
                    print(f"     éªŒè¯è·¯å¾„: {detail['verified_path']}")
        
        if stats['valid_slices'] == 0:
            logger.error("âŒ æ²¡æœ‰æœ‰æ•ˆçš„åˆ‡ç‰‡æ•°æ®ï¼")
            return 0, 0, stats, []
        
        logger.info(f"å¼€å§‹å¤„ç† {len(df)} ä¸ªåˆ‡ç‰‡...")
        
        # å‡†å¤‡å¤„ç†ä»»åŠ¡
        tasks = []
        for idx, row in df.iterrows():
            tasks.append((idx, row))
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
        success_count = 0
        fail_count = 0
        fail_details = []
        
        with tqdm(total=len(tasks), desc="å¤„ç†è¿›åº¦", unit="åˆ‡ç‰‡") as pbar:
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                future_to_idx = {}
                for idx, row in tasks:
                    future = executor.submit(self.process_single_slice, row, idx)
                    future_to_idx[future] = idx
                
                # å¤„ç†ç»“æœ
                for future in as_completed(future_to_idx):
                    idx = future_to_idx[future]
                    try:
                        success, message = future.result(timeout=30)
                        if success:
                            success_count += 1
                        else:
                            fail_count += 1
                            fail_details.append((idx, message))
                    except Exception as e:
                        fail_count += 1
                        fail_details.append((idx, f"å¤„ç†å¼‚å¸¸: {str(e)}"))
                        logger.error(f"åˆ‡ç‰‡ {idx} å¤„ç†å¼‚å¸¸: {str(e)}")
                    
                    pbar.update(1)
                    pbar.set_postfix_str(f"æˆåŠŸ: {success_count}, å¤±è´¥: {fail_count}")
        
        return success_count, fail_count, stats, fail_details


def verify_sliced_videos(slice_video_dir: str):
    """éªŒè¯åˆ‡ç‰‡è§†é¢‘æ–‡ä»¶"""
    print("\n" + "=" * 60)
    print("éªŒè¯åˆ‡ç‰‡è§†é¢‘æ–‡ä»¶...")
    print("=" * 60)
    
    if not os.path.exists(slice_video_dir):
        print(f"âŒ åˆ‡ç‰‡è§†é¢‘ç›®å½•ä¸å­˜åœ¨: {slice_video_dir}")
        return 0, 0
    
    # æŸ¥æ‰¾æ‰€æœ‰åˆ‡ç‰‡è§†é¢‘æ–‡ä»¶
    slice_files = []
    slice_sizes = {}
    total_size_mb = 0
    
    for root, dirs, files in os.walk(slice_video_dir):
        for file in files:
            if file.endswith('.mp4'):
                slice_path = os.path.join(root, file)
                rel_path = os.path.relpath(slice_path, slice_video_dir)
                file_size_mb = os.path.getsize(slice_path) / (1024 * 1024)  # MB
                slice_files.append(rel_path)
                slice_sizes[rel_path] = file_size_mb
                total_size_mb += file_size_mb
    
    print(f"æ‰¾åˆ° {len(slice_files)} ä¸ªåˆ‡ç‰‡è§†é¢‘æ–‡ä»¶")
    
    if slice_files:
        # è®¡ç®—å¹³å‡å¤§å°
        avg_size_mb = total_size_mb / len(slice_files) if slice_files else 0
        
        print(f"æ€»å¤§å°: {total_size_mb:.2f} MB")
        print(f"å¹³å‡å¤§å°: {avg_size_mb:.2f} MB")
        
        print("\nåˆ‡ç‰‡è§†é¢‘æ–‡ä»¶ç¤ºä¾‹:")
        for i, rel_path in enumerate(slice_files[:5], 1):
            size = slice_sizes[rel_path]
            # æå–åˆ‡ç‰‡æ—¶é—´ä¿¡æ¯
            time_match = re.search(r"slice_(\d+)_(\d+)\.mp4$", rel_path)
            if time_match:
                seg_start, seg_end = time_match.groups()
                time_info = f"{seg_start}-{seg_end}s"
            else:
                time_info = "æœªçŸ¥æ—¶é—´"
            print(f"  {i}. {time_info} - {rel_path} ({size:.2f} MB)")
        
        if len(slice_files) > 5:
            print(f"  ... è¿˜æœ‰ {len(slice_files) - 5} ä¸ªæ–‡ä»¶")
    
    return len(slice_files), total_size_mb


def main():
    """ä¸»å‡½æ•° - å¤„ç†åˆ‡ç‰‡è§†é¢‘"""
    SLICE_INFO_CSV = "/root/workspace/downloaded_videos_for_segment/slice_info.csv"
    SLICE_VIDEO_DIR = "/root/workspace/downloaded_videos_for_segment/sliced_videos"
    OUTPUT_BASE_DIR = "/root/workspace/sliced_vqa_annotations"
    
    print("=" * 60)
    print("ğŸ¯ åˆ‡ç‰‡è§†é¢‘æ ‡æ³¨ç”Ÿæˆå·¥å…·")
    print("=" * 60)
    print(f"ğŸ“ åˆ‡ç‰‡è§†é¢‘ç›®å½•: {SLICE_VIDEO_DIR}")
    print(f"ğŸ“„ åˆ‡ç‰‡ä¿¡æ¯CSV: {SLICE_INFO_CSV}")
    print(f"ğŸ“¦ è¾“å‡ºç›®å½•: {OUTPUT_BASE_DIR}")
    print("=" * 60)
    print("ğŸ“‹ åŠŸèƒ½è¯´æ˜:")
    print("  - è¯»å–åˆ‡ç‰‡ä¿¡æ¯CSVæ–‡ä»¶")
    print("  - éªŒè¯åˆ‡ç‰‡è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
    print("  - æŒ‰ç±»åˆ«ç”Ÿæˆåˆ‡ç‰‡è§†é¢‘æ ‡æ³¨æ–‡æ¡£")
    print("  - ä¸ºæŠ½å¸§æä¾›ç²¾ç¡®çš„åˆ‡ç‰‡è§†é¢‘è·¯å¾„")
    print("=" * 60)
    
    # éªŒè¯åˆ‡ç‰‡è§†é¢‘æ–‡ä»¶
    slice_count, total_size_mb = verify_sliced_videos(SLICE_VIDEO_DIR)
    if slice_count == 0:
        logger.warning("æœªæ‰¾åˆ°åˆ‡ç‰‡è§†é¢‘æ–‡ä»¶ï¼Œä½†æ ‡æ³¨ç”Ÿæˆå°†ç»§ç»­è¿›è¡Œ")
    
    # æ£€æŸ¥åˆ‡ç‰‡ä¿¡æ¯CSVæ–‡ä»¶
    if not os.path.exists(SLICE_INFO_CSV):
        logger.error(f"åˆ‡ç‰‡ä¿¡æ¯CSVæ–‡ä»¶ä¸å­˜åœ¨: {SLICE_INFO_CSV}")
        logger.info(f"è¯·å…ˆè¿è¡Œè§†é¢‘ä¸‹è½½å’Œåˆ‡ç‰‡è„šæœ¬ç”Ÿæˆåˆ‡ç‰‡ä¿¡æ¯")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(OUTPUT_BASE_DIR, exist_ok=True)
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = SlicedVideoAnnotationProcessor(
        slice_info_csv=SLICE_INFO_CSV,
        slice_video_dir=SLICE_VIDEO_DIR,
        output_base_dir=OUTPUT_BASE_DIR
    )
    
    # å¤„ç†æ‰€æœ‰æ•°æ®
    start_time = time.time()
    success_count, fail_count, data_stats, fail_details = processor.process_all(max_workers=4)
    elapsed_time = time.time() - start_time
    
    # ä¿å­˜ç»“æœ
    if processor.annotations:
        total_annotations = processor.save_annotations()
        processor.save_slice_mapping()
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        stats = processor.save_statistics(success_count, fail_count, data_stats, fail_details, elapsed_time)
    else:
        total_annotations = 0
        logger.warning("æ²¡æœ‰ç”Ÿæˆä»»ä½•åˆ‡ç‰‡æ ‡æ³¨æ•°æ®")
        stats = processor.save_statistics(success_count, fail_count, data_stats, fail_details, elapsed_time)
    
    # è¾“å‡ºç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ‰ åˆ‡ç‰‡æ ‡æ³¨ç”Ÿæˆå®Œæˆ")
    print("=" * 60)
    print(f"â±ï¸  æ€»è€—æ—¶: {elapsed_time:.2f}ç§’")
    print(f"ğŸ“Š æ€»è®¡å¤„ç†: {success_count + fail_count} ä¸ªåˆ‡ç‰‡")
    print(f"âœ… æˆåŠŸ: {success_count} ä¸ªåˆ‡ç‰‡")
    print(f"âŒ å¤±è´¥: {fail_count} ä¸ªåˆ‡ç‰‡")
    
    if success_count > 0:
        print(f"\nğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_BASE_DIR}")
        print("ç›®å½•ç»“æ„:")
        print(f"  {OUTPUT_BASE_DIR}/")
        print(f"  â”œâ”€â”€ sliced_annotations/         # åˆ‡ç‰‡æ ‡æ³¨æ–‡ä»¶")
        print(f"  â”‚   â”œâ”€â”€ all_sliced_annotations.json  # æ‰€æœ‰åˆ‡ç‰‡æ ‡æ³¨çš„åˆå¹¶æ–‡ä»¶")
        print(f"  â”‚   â”œâ”€â”€ summary.json           # æ±‡æ€»ä¿¡æ¯")
        print(f"  â”‚   â””â”€â”€ [ç±»åˆ«].json           # æ¯ä¸ªç±»åˆ«çš„åˆ‡ç‰‡æ ‡æ³¨")
        print(f"  â”œâ”€â”€ slice_mapping.json         # åˆ‡ç‰‡è§†é¢‘è·¯å¾„æ˜ å°„")
        print(f"  â””â”€â”€ sliced_processing_statistics.json  # å¤„ç†ç»Ÿè®¡")
        
        # æ˜¾ç¤ºç”Ÿæˆçš„ç±»åˆ«
        if processor.annotations:
            print(f"\nğŸ“‚ ç”Ÿæˆçš„åˆ‡ç‰‡æ ‡æ³¨ç±»åˆ« ({len(processor.annotations)} ä¸ª):")
            for label, annotations in sorted(processor.annotations.items(), 
                                          key=lambda x: len(x[1]), reverse=True)[:10]:
                print(f"  - {label}: {len(annotations)} ä¸ªåˆ‡ç‰‡")
            if len(processor.annotations) > 10:
                print(f"  ... è¿˜æœ‰ {len(processor.annotations) - 10} ä¸ªç±»åˆ«")
        
        print(f"\nğŸ“‹ ä¸‹ä¸€æ­¥:")
        print("1. æ£€æŸ¥åˆ‡ç‰‡æ ‡æ³¨æ–‡ä»¶: ls -la /root/workspace/sliced_vqa_annotations/sliced_annotations/")
        print("2. æŸ¥çœ‹åˆ‡ç‰‡æ ‡æ³¨ç»Ÿè®¡: cat /root/workspace/sliced_vqa_annotations/sliced_processing_statistics.json | python -m json.tool")
        print("3. å¯¹åˆ‡ç‰‡è§†é¢‘è¿›è¡ŒæŠ½å¸§: python /root/workspace/LLaMA-Factory/scene_tag/1.5_get_frames_squeeze.py -i /root/workspace/downloaded_videos_2fps/sliced_videos")
        print("4. ä½¿ç”¨åˆ‡ç‰‡æ ‡æ³¨è¿›è¡Œæ¨¡å‹è®­ç»ƒ")
        
        # æ˜¾ç¤ºåˆ‡ç‰‡æ ‡æ³¨ç¤ºä¾‹
        print(f"\nğŸ“ åˆ‡ç‰‡æ ‡æ³¨ç¤ºä¾‹:")
        for label, annotations in sorted(processor.annotations.items(), 
                                      key=lambda x: len(x[1]), reverse=True):
            if annotations:
                anno = annotations[0]
                print(f"  ç±»åˆ«: {label}")
                print(f"    åˆ‡ç‰‡è§†é¢‘: {os.path.basename(anno.get('slice_video_path', 'N/A'))}")
                print(f"    åˆ‡ç‰‡çª—å£: {anno['slice_window'][0]}s-{anno['slice_window'][1]}s (åŸå§‹è§†é¢‘)")
                print(f"    åŠ¨ä½œæ—¶é—´: {anno['time_range_in_slice'][0]}s-{anno['time_range_in_slice'][1]}s (åˆ‡ç‰‡ä¸­)")
                print(f"    æ–‡ä»¶å­˜åœ¨: {anno.get('video_exists', False)}")
                break
    else:
        print(f"\nâŒ å¤„ç†å¤±è´¥ï¼Œæ²¡æœ‰ç”Ÿæˆä»»ä½•åˆ‡ç‰‡æ ‡æ³¨æ•°æ®")
        print("å¯èƒ½çš„åŸå› :")
        print("1. åˆ‡ç‰‡ä¿¡æ¯CSVæ–‡ä»¶æ ¼å¼é”™è¯¯")
        print("2. æ‰€æœ‰è¡Œéƒ½æœ‰æ•°æ®é—®é¢˜")
        print("3. æ²¡æœ‰æœ‰æ•ˆçš„åˆ‡ç‰‡è¡Œ")
        print(f"\nğŸ” æŸ¥çœ‹è¯¦ç»†æ—¥å¿—: tail -100 /root/workspace/sliced_video_annotation.log")
    
    print("=" * 60)


if __name__ == "__main__":
    main()