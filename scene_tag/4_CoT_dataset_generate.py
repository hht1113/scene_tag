import os
import json
import random
import time
import base64
from typing import Dict, List, Optional, Tuple
import logging
from datetime import datetime
from tqdm import tqdm
import dashscope
from dashscope import MultiModalConversation
import traceback

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/root/workspace/cot_generation.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ç”¨æˆ·é—®é¢˜åˆ—è¡¨
QUESTION_LIST = [
    "Analyze the driving scenario strictly.",
    "Classify the ego vehicle's behavior.",
    "Give me the hierarchical tag for this clip.",
    "Identify the current driving maneuver.",
    "Determine the scene category for the ego vehicle.",
    "Perform a scenario classification for this video.",
    "What is the standard tag for this driving situation?",
    "Annotate this clip with the correct scenario label.",
    "What is the car doing right now?",
    "Describe the current traffic situation and the ego car's action.",
    "Why did the car stop or maneuver like this?",
    "What is happening in front of the ego vehicle?",
    "Can you explain the ego vehicle's current behavior?",
    "Interpret the driving scene shown in the video.",
    "Look at the video and tell me what the scenario is.",
    "What kind of intersection or road event is this?"
]

class CotGenerator:
    """CoTç”Ÿæˆå™¨ï¼Œä½¿ç”¨å®Œæ•´çš„15å¸§åºåˆ—"""
    
    def __init__(self, api_key: str, max_frames: int = 15):
        self.api_key = api_key
        self.model_name = "qwen-vl-plus"
        self.max_retries = 3
        self.retry_delay = 2
        self.max_frames = max_frames
        
        # è®¾ç½®APIå¯†é’¥
        dashscope.api_key = api_key
    
    def encode_image_to_base64(self, image_path: str) -> Optional[str]:
        """å°†å›¾ç‰‡ç¼–ç ä¸ºbase64"""
        try:
            with open(image_path, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode('utf-8')
        except Exception as e:
            logger.error(f"ç¼–ç å›¾ç‰‡å¤±è´¥ {image_path}: {str(e)}")
            return None
    
    def generate_cot(self, frame_paths: List[str], true_label: str) -> Tuple[Optional[Dict], str]:
        """ç”ŸæˆCoTåˆ†æï¼ˆä½¿ç”¨å®Œæ•´çš„15å¸§åºåˆ—ï¼‰"""
        if not frame_paths:
            return None, "æ²¡æœ‰å›¾ç‰‡å¸§"
        
        # ç¡®ä¿å¸§æ•°ä¸è¶…è¿‡é™åˆ¶
        if len(frame_paths) > self.max_frames:
            logger.warning(f"å¸§æ•°è¶…è¿‡é™åˆ¶ ({len(frame_paths)} > {self.max_frames})ï¼Œæˆªå–å‰{self.max_frames}å¸§")
            frame_paths = frame_paths[:self.max_frames]
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        valid_frames = []
        for i, frame_path in enumerate(frame_paths):
            if os.path.exists(frame_path):
                valid_frames.append(frame_path)
            else:
                logger.warning(f"å¸§æ–‡ä»¶ä¸å­˜åœ¨: {frame_path}")
        
        if not valid_frames:
            return None, "æ‰€æœ‰å¸§æ–‡ä»¶éƒ½ä¸å­˜åœ¨"
        
        # è®°å½•å¸§çš„æ—¶åºä¿¡æ¯
        total_frames = len(valid_frames)
        logger.info(f"ä½¿ç”¨{total_frames}å¸§è¿›è¡Œåˆ†æï¼Œæ—¶é—´é¡ºåº: å¸§1 â†’ å¸§{total_frames}")
        
        # æ„å»ºæ¶ˆæ¯
        user_prompt = f"""Here are {total_frames} consecutive frames from a driving video clip, showing the complete scenario in strict temporal order (Frame 1 â†’ Frame {total_frames}).
The GROUND TRUTH label for this scenario is: **"{true_label}"**

Please analyze the entire sequence of {total_frames} frames in chronological order to generate a comprehensive "Chain of Thought" analysis that strictly supports this label.
Your response must be a valid JSON object with the following fields:

1.  **"Observation"**: Describe the visual scene across all frames in chronological order. Focus on:
    * Road geometry and its changes throughout the sequence
    * Traffic control devices (lights, signs) and their state changes
    * Positions, movements, and trajectories of all relevant agents (vehicles, VRUs)
    * Temporal progression and dynamic changes between consecutive frames
    * Spatial relationships between objects and how they evolve
    * *Constraint*: Do not mention the label name. Describe what you see in the complete sequence.

2.  **"Reasoning"**: Connect the complete sequence of observations to the label:
    * Explain the causal relationships and decision-making process
    * Describe the temporal dynamics and key events in order
    * Identify critical moments and their timing in the sequence
    * Explain how the entire sequence justifies the label

3.  **"Tag"**: Exactly output: "{true_label}"

**Important Constraints:**
* Analyze all {total_frames} frames in chronological order
* Consider the complete temporal dynamics and causality
* Base analysis on visual evidence, but trust the ground truth
* The "Observation" must imply the "Tag" without explicitly stating it
* Output only valid JSON."""
        
        for attempt in range(self.max_retries):
            try:
                # æ„å»ºæ¶ˆæ¯å†…å®¹ - æŒ‰é¡ºåºæ·»åŠ æ‰€æœ‰å›¾ç‰‡
                message_content = []
                
                # æŒ‰é¡ºåºæ·»åŠ æ‰€æœ‰å›¾ç‰‡
                for i, frame_path in enumerate(valid_frames):
                    image_base64 = self.encode_image_to_base64(frame_path)
                    if image_base64:
                        message_content.append({
                            'image': f"data:image/jpeg;base64,{image_base64}"
                        })
                
                if not message_content:
                    return None, "æ— æ³•ç¼–ç ä»»ä½•å›¾ç‰‡"
                
                # æ·»åŠ æ–‡æœ¬æç¤º
                message_content.append({
                    'text': user_prompt
                })
                
                messages = [
                    {
                        'role': 'user',
                        'content': message_content
                    }
                ]
                
                logger.info(f"å‘é€{len(valid_frames)}å¸§ï¼ˆå®Œæ•´åºåˆ—ï¼‰è¿›è¡Œåˆ†æ")
                
                # å¢åŠ æœ€å¤§tokensï¼Œå› ä¸º15å¸§éœ€è¦æ›´è¯¦ç»†çš„åˆ†æ
                response = MultiModalConversation.call(
                    model=self.model_name,
                    messages=messages,
                    max_tokens=3000
                )
                
                if response.status_code == 200:
                    cot_text = response.output.choices[0].message.content[0]['text']
                    
                    # æå–å’Œè§£æJSON
                    try:
                        import re
                        json_match = re.search(r'\{.*\}', cot_text, re.DOTALL)
                        if json_match:
                            cot_json = json.loads(json_match.group())
                        else:
                            cot_json = json.loads(cot_text)
                        
                        # éªŒè¯JSONç»“æ„
                        required_fields = ["Observation", "Reasoning", "Tag"]
                        for field in required_fields:
                            if field not in cot_json:
                                raise ValueError(f"ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
                        
                        if cot_json["Tag"] != true_label:
                            logger.warning(f"æ ‡ç­¾ä¸åŒ¹é…: æœŸæœ› {true_label}, å¾—åˆ° {cot_json['Tag']}")
                            cot_json["Tag"] = true_label
                        
                        # æ·»åŠ å¸§ä¿¡æ¯
                        cot_json["frames_used"] = len(valid_frames)
                        cot_json["frame_sequence"] = "å®Œæ•´æ—¶åºåºåˆ—"
                        cot_json["frame_count"] = len(frame_paths)
                        
                        return cot_json, ""
                        
                    except json.JSONDecodeError as e:
                        logger.warning(f"ç¬¬{attempt+1}æ¬¡å°è¯•: JSONè§£æå¤±è´¥: {e}")
                        if attempt < self.max_retries - 1:
                            time.sleep(self.retry_delay)
                            continue
                        else:
                            return None, f"æ— æ³•è§£æJSONå“åº”: {str(e)}"
                else:
                    error_msg = f"APIè°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}, æ¶ˆæ¯: {response.message}"
                    logger.error(f"ç¬¬{attempt+1}æ¬¡å°è¯•: {error_msg}")
                    
                    if attempt < self.max_retries - 1:
                        time.sleep(self.retry_delay)
                        continue
                    else:
                        return None, error_msg
                        
            except Exception as e:
                logger.error(f"ç¬¬{attempt+1}æ¬¡å°è¯•: APIè°ƒç”¨å¤±è´¥: {str(e)}")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay)
                else:
                    return None, f"APIè°ƒç”¨å¤±è´¥: {str(e)}"
        
        return None, "æ‰€æœ‰å°è¯•éƒ½å¤±è´¥"

class DatasetBuilder:
    """æ•°æ®é›†æ„å»ºå™¨ï¼Œåˆ›å»ºæŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼ˆä½¿ç”¨æŠ½å¸§å›¾ç‰‡ï¼‰"""
    
    def __init__(self, data_dir: str, output_dir: str):
        self.data_dir = data_dir
        self.output_dir = output_dir
        self.processed_data = []
        self.failed_samples = []
        
    def load_samples(self, data_file: str = "simple_dataset.json") -> List[Dict]:
        """åŠ è½½æ ·æœ¬æ•°æ®"""
        file_path = os.path.join(self.data_dir, "converted_annotations", data_file)
        
        if not os.path.exists(file_path):
            logger.error(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return []
        
        with open(file_path, 'r', encoding='utf-8') as f:
            samples = json.load(f)
        
        logger.info(f"åŠ è½½äº† {len(samples)} ä¸ªæ ·æœ¬")
        return samples
    
    def build_finetuning_sample(self, sample: Dict, cot_result: Dict) -> Dict:
        """æ„å»ºå•æ¡å¾®è°ƒæ ·æœ¬ï¼ˆä½¿ç”¨å®Œæ•´çš„15å¸§åºåˆ—ï¼‰"""
        # éšæœºé€‰æ‹©ä¸€ä¸ªç”¨æˆ·é—®é¢˜
        user_question = random.choice(QUESTION_LIST)
        
        # è·å–å¸§è·¯å¾„
        frame_paths = sample.get("frame_paths", [])
        if not frame_paths:
            return None
        
        # ç¡®ä¿å¸§è·¯å¾„æ˜¯ç»å¯¹è·¯å¾„
        absolute_frame_paths = []
        for rel_path in frame_paths:
            abs_path = os.path.join(self.data_dir, rel_path)
            if os.path.exists(abs_path):
                absolute_frame_paths.append(abs_path)
        
        if not absolute_frame_paths:
            logger.warning(f"æ ·æœ¬ {sample.get('id')} æ²¡æœ‰æœ‰æ•ˆçš„å¸§æ–‡ä»¶")
            return None
        
        # ä¿æŒå®Œæ•´çš„15å¸§åºåˆ—
        MAX_FRAMES = 15
        if len(absolute_frame_paths) > MAX_FRAMES:
            logger.warning(f"å¸§æ•°è¶…è¿‡{MAX_FRAMES}ï¼Œæˆªå–å‰{MAX_FRAMES}å¸§")
            selected_frames = absolute_frame_paths[:MAX_FRAMES]
        else:
            selected_frames = absolute_frame_paths
        
        logger.info(f"æ„å»ºæ ·æœ¬ {sample.get('id')}: ä½¿ç”¨{len(selected_frames)}å¸§ï¼ˆå®Œæ•´æ—¶åºï¼‰")
        
        # æ„å»ºdashscopeæ ¼å¼çš„å¯¹è¯
        message_content = []
        for i, img_path in enumerate(selected_frames):
            # ç¼–ç å›¾ç‰‡ä¸ºbase64
            try:
                with open(img_path, "rb") as image_file:
                    image_base64 = base64.b64encode(image_file.read()).decode('utf-8')
                message_content.append({
                    "image": f"data:image/jpeg;base64,{image_base64}"
                })
            except Exception as e:
                logger.error(f"ç¼–ç å›¾ç‰‡å¤±è´¥ {img_path}: {str(e)}")
                continue
        
        if not message_content:
            logger.warning(f"æ— æ³•ç¼–ç ä»»ä½•å›¾ç‰‡: {sample.get('id')}")
            return None
        
        message_content.append({
            "text": user_question
        })
        
        conversations = [
            {
                "role": "user",
                "content": message_content
            },
            {
                "role": "assistant",
                "content": [
                    {
                        "text": json.dumps(cot_result, ensure_ascii=False)
                    }
                ]
            }
        ]
        
        return {
            "id": sample.get("id", ""),
            "question": user_question,
            "frame_paths": selected_frames,
            "total_frames": len(absolute_frame_paths),
            "frames_used": len(selected_frames),
            "label_zh": sample.get("label_zh", ""),
            "label_en": sample.get("label_en", ""),
            "conversations": conversations,
            "cot": cot_result
        }
    
    def process_samples(self, samples: List[Dict], generator: CotGenerator, 
                       max_workers: int = 2, max_samples: int = None):
        """å¤„ç†æ ·æœ¬ï¼Œç”ŸæˆCoTï¼ˆä½¿ç”¨å®Œæ•´çš„15å¸§åºåˆ—ï¼‰"""
        if max_samples:
            samples = samples[:max_samples]
        
        logger.info(f"å¼€å§‹å¤„ç† {len(samples)} ä¸ªæ ·æœ¬ï¼Œä½¿ç”¨å®Œæ•´15å¸§æ—¶åºåºåˆ—")
        
        # é¡ºåºå¤„ç†ï¼Œé¿å…APIé™åˆ¶
        for i, sample in enumerate(tqdm(samples, desc="ç”ŸæˆCoT")):
            try:
                sample_id = sample.get("id", f"sample_{i}")
                label_en = sample.get("label_en", "")
                frame_paths = sample.get("frame_paths", [])
                
                if not frame_paths:
                    logger.warning(f"æ ·æœ¬ {sample_id} æ²¡æœ‰å¸§è·¯å¾„ï¼Œè·³è¿‡")
                    self.failed_samples.append({
                        "id": sample_id,
                        "reason": "æ²¡æœ‰å¸§è·¯å¾„"
                    })
                    continue
                
                # å°†ç›¸å¯¹è·¯å¾„è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
                absolute_frame_paths = []
                for rel_path in frame_paths:
                    abs_path = os.path.join(self.data_dir, rel_path)
                    if os.path.exists(abs_path):
                        absolute_frame_paths.append(abs_path)
                
                if not absolute_frame_paths:
                    logger.warning(f"æ ·æœ¬ {sample_id} æ²¡æœ‰æœ‰æ•ˆçš„å¸§æ–‡ä»¶ï¼Œè·³è¿‡")
                    self.failed_samples.append({
                        "id": sample_id,
                        "reason": "å¸§æ–‡ä»¶ä¸å­˜åœ¨"
                    })
                    continue
                
                # è®°å½•å¸§çš„æ—¶åºä¿¡æ¯
                logger.info(f"å¤„ç†æ ·æœ¬ {i+1}/{len(samples)}: {sample_id} (åŒ…å«{len(absolute_frame_paths)}å¸§ï¼Œæ—¶é—´é¡ºåº: 1â†’{len(absolute_frame_paths)})")
                
                # ç”ŸæˆCoT
                start_time = time.time()
                cot_result, error = generator.generate_cot(absolute_frame_paths, label_en)
                end_time = time.time()
                
                logger.info(f"CoTç”Ÿæˆè€—æ—¶: {end_time - start_time:.2f}ç§’")
                
                if cot_result:
                    # æ„å»ºå¾®è°ƒæ ·æœ¬
                    finetuning_sample = self.build_finetuning_sample(sample, cot_result)
                    if finetuning_sample:
                        self.processed_data.append(finetuning_sample)
                        logger.info(f"æˆåŠŸç”ŸæˆCoT: {sample_id} (ä½¿ç”¨{len(absolute_frame_paths)}å¸§)")
                    else:
                        self.failed_samples.append({
                            "id": sample_id,
                            "reason": "æ— æ³•æ„å»ºå¾®è°ƒæ ·æœ¬"
                        })
                else:
                    self.failed_samples.append({
                        "id": sample_id,
                        "reason": error
                    })
                    logger.error(f"ç”ŸæˆCoTå¤±è´¥ {sample_id}: {error}")
                
                # é¿å…APIé™åˆ¶ï¼Œå¢åŠ å»¶è¿Ÿ
                if i < len(samples) - 1:
                    wait_time = 3  # 3ç§’å»¶è¿Ÿï¼Œ15å¸§å¤„ç†æ›´è€—æ—¶
                    logger.info(f"ç­‰å¾…{wait_time}ç§’åå¤„ç†ä¸‹ä¸€ä¸ªæ ·æœ¬...")
                    time.sleep(wait_time)
                    
            except Exception as e:
                logger.error(f"å¤„ç†æ ·æœ¬å¤±è´¥ {sample.get('id', f'sample_{i}')}: {str(e)}")
                logger.error(traceback.format_exc())
                self.failed_samples.append({
                    "id": sample.get("id", f"sample_{i}"),
                    "reason": f"å¼‚å¸¸: {str(e)}"
                })
    
    def save_results(self):
        """ä¿å­˜ç»“æœ"""
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path = os.path.join(self.output_dir, "finetuning_dataset")
        os.makedirs(output_path, exist_ok=True)
        
        # 1. ä¿å­˜å®Œæ•´æ•°æ®é›†
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = os.path.join(output_path, f"cot_dataset_{timestamp}.json")
        
        dataset = {
            "version": "3.0.0",
            "description": "Qwen-VL finetuning dataset with CoT reasoning (Frame Input)",
            "created": datetime.now().isoformat(),
            "statistics": {
                "total_samples": len(self.processed_data),
                "failed_samples": len(self.failed_samples),
                "success_rate": len(self.processed_data) / (len(self.processed_data) + len(self.failed_samples)) if self.processed_data else 0
            },
            "data": self.processed_data
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(dataset, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ä¿å­˜å®Œæ•´æ•°æ®é›†: {output_file} ({len(self.processed_data)} ä¸ªæ ·æœ¬)")
        
        # 2. ä¿å­˜å¤±è´¥æ ·æœ¬
        if self.failed_samples:
            failed_file = os.path.join(output_path, f"failed_samples_{timestamp}.json")
            with open(failed_file, 'w', encoding='utf-8') as f:
                json.dump(self.failed_samples, f, ensure_ascii=False, indent=2)
            logger.info(f"ä¿å­˜å¤±è´¥æ ·æœ¬: {failed_file} ({len(self.failed_samples)} ä¸ª)")
        
        # 3. ä¿å­˜ç®€åŒ–æ ¼å¼
        simple_data = []
        for sample in self.processed_data:
            simple_item = {
                "id": sample["id"],
                "question": sample["question"],
                "frames_used": sample["frames_used"],
                "total_frames": sample["total_frames"],
                "label_en": sample["label_en"],
                "cot": sample["cot"]
            }
            simple_data.append(simple_item)
        
        simple_file = os.path.join(output_path, f"simple_cot_dataset_{timestamp}.json")
        with open(simple_file, 'w', encoding='utf-8') as f:
            json.dump(simple_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ä¿å­˜ç®€åŒ–æ•°æ®é›†: {simple_file}")
        
        return output_path

def main():
    """ä¸»å‡½æ•°"""
    DATA_DIR = "/root/workspace/vqa_dataset_prepared"
    OUTPUT_DIR = "/root/workspace/vqa_dataset_cot"
    API_KEY = os.getenv("DASHSCOPE_API_KEY")
    
    print("=" * 60)
    print("CoTæŒ‡ä»¤æ•°æ®é›†ç”Ÿæˆå·¥å…·ï¼ˆæŠ½å¸§å›¾ç‰‡ç‰ˆæœ¬ï¼‰")
    print("=" * 60)
    print(f"ğŸ“ æ•°æ®ç›®å½•: {DATA_DIR}")
    print(f"ğŸ“¦ è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    
    # æ£€æŸ¥APIå¯†é’¥
    if not API_KEY:
        logger.error("è¯·è®¾ç½®DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
        print("è¯·è®¾ç½®ç¯å¢ƒå˜é‡: export DASHSCOPE_API_KEY='your-api-key'")
        return
    
    # æ£€æŸ¥æ•°æ®ç›®å½•
    if not os.path.exists(DATA_DIR):
        logger.error(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {DATA_DIR}")
        print("è¯·å…ˆè¿è¡Œæ ‡ç­¾è½¬æ¢å’ŒæŠ½å¸§è„šæœ¬")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # åˆå§‹åŒ–ç”Ÿæˆå™¨å’Œæ•°æ®é›†æ„å»ºå™¨
    generator = CotGenerator(api_key=API_KEY, max_frames=15)
    builder = DatasetBuilder(data_dir=DATA_DIR, output_dir=OUTPUT_DIR)
    
    # åŠ è½½æ ·æœ¬
    samples = builder.load_samples("simple_dataset.json")
    if not samples:
        logger.error("æ²¡æœ‰æ‰¾åˆ°æ ·æœ¬æ•°æ®")
        return
    
    # å¤„ç†æ ·æœ¬ï¼ˆå¯ä»¥è®¾ç½®max_samplesé™åˆ¶å¤„ç†æ•°é‡ï¼Œç”¨äºæµ‹è¯•ï¼‰
    max_samples = None  # è®¾ä¸ºNoneå¤„ç†æ‰€æœ‰æ ·æœ¬ï¼Œæˆ–è®¾ä¸ºæ•°å­—æµ‹è¯•
    if max_samples:
        print(f"âš ï¸  æµ‹è¯•æ¨¡å¼: åªå¤„ç†å‰ {max_samples} ä¸ªæ ·æœ¬")
    
    builder.process_samples(
        samples=samples,
        generator=generator,
        max_workers=1,  # é¡ºåºå¤„ç†é¿å…APIé™åˆ¶
        max_samples=max_samples
    )
    
    # ä¿å­˜ç»“æœ
    output_path = builder.save_results()
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 60)
    print("ğŸ‰ CoTæ•°æ®é›†ç”Ÿæˆå®Œæˆï¼ˆæŠ½å¸§å›¾ç‰‡ç‰ˆæœ¬ï¼‰")
    print("=" * 60)
    
    total_processed = len(builder.processed_data) + len(builder.failed_samples)
    success_count = len(builder.processed_data)
    fail_count = len(builder.failed_samples)
    
    print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:")
    print(f"  âœ… æˆåŠŸ: {success_count}")
    print(f"  âŒ å¤±è´¥: {fail_count}")
    print(f"  ğŸ“ˆ æˆåŠŸç‡: {success_count/total_processed*100:.1f}%" if total_processed > 0 else "0%")
    
    print(f"\nğŸ“ è¾“å‡ºç›®å½•: {output_path}")
    print("ç”Ÿæˆçš„æ–‡ä»¶:")
    for file in os.listdir(output_path):
        file_path = os.path.join(output_path, file)
        if os.path.isfile(file_path):
            size_mb = os.path.getsize(file_path) / (1024 * 1024)
            print(f"  - {file} ({size_mb:.2f} MB)")
    
    print(f"\nğŸ“‹ æ•°æ®é›†æ ¼å¼ç¤ºä¾‹:")
    if builder.processed_data:
        sample = builder.processed_data[0]
        print(f"\næ ·æœ¬ID: {sample['id']}")
        print(f"é—®é¢˜: {sample['question']}")
        print(f"ä½¿ç”¨å¸§æ•°: {sample['frames_used']}/{sample['total_frames']}")
        print(f"æ ‡ç­¾: {sample['label_en']}")
        print(f"CoT:")
        cot = sample['cot']
        print(f"  Observation: {cot.get('Observation', '')[:100]}...")
        print(f"  Reasoning: {cot.get('Reasoning', '')[:100]}...")
        print(f"  Tag: {cot.get('Tag', '')}")
    
    print(f"\nğŸš€ ç‰¹ç‚¹:")
    print("âœ“ ä½¿ç”¨æŠ½å¸§åçš„å›¾ç‰‡ï¼Œé¿å…è§†é¢‘å¤„ç†é—®é¢˜")
    print("âœ“ ç²¾ç¡®æ§åˆ¶å¸§åºåˆ—ï¼Œæ”¯æŒæ—¶é—´åºåˆ—åˆ†æ")
    print("âœ“ è‡ªåŠ¨é€‰æ‹©å…³é”®å¸§ï¼Œä¼˜åŒ–APIä½¿ç”¨æ•ˆç‡")
    print("âœ“ æ›´ç¨³å®šçš„å¤„ç†æµç¨‹")
    
    print("=" * 60)

if __name__ == "__main__":
    main()