import os
import json
import random
from typing import Dict, List, Tuple
import logging
from datetime import datetime
from tqdm import tqdm
from collections import defaultdict

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/root/workspace/llama_factory_dataset_generation.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# System Promptå®šä¹‰
SYSTEM_PROMPT = """You are an expert in autonomous driving scene annotation. 
Based on a 60-second video, you need to identify the ego vehicle's actions. 

You MUST choose labels ONLY from this specific list:
1. TrafficLight_Straight_StopGo
2. TrafficLight_LeftTurn_StopGo
3. LaneChange_ForIntersection
4. Avoid_SlowVRU
5. Avoid_StaticVehicle
6. Avoid_ConstructionZone
7. VRU_CrossingPath
8. Vehicle_CrossingPath
9. Vehicle_CutIn
10. Vehicle_AggressiveCutIn
11. VRU_SuddenCutIn
12. VRU_SlowCutIn
13. LeadVehicle_EmergencyBrake
14. Start_FromMainRoad
15. Park_Roadside
16. U_Turn_Standard
17. U_Turn_ThreePoint
18. LeftTurn_VRU_Crossing
19. Lane_Cruising_Straight

Please use the format: <driving_maneuver>action_label</driving_maneuver> from <start_time>start_time_value</start_time> to <end_time>end_time_value</end_time> seconds.
If there are multiple actions, list them in chronological order separated by " and ".
IMPORTANT: Only use the exact labels from the list above. Do NOT create new labels."""

# é—®é¢˜æ¨¡æ¿åˆ—è¡¨ - åœ¨è§†é¢‘å‰æ·»åŠ <video>æ ‡è®°
ENGLISH_QUESTION_TEMPLATES = [
    "<video>\nWhat is the ego vehicle's action in the video?",
    "<video>\nWhat is the ego vehicle doing in this video clip?",
    "<video>\nWhat is the behavior of the ego vehicle?",
    "<video>\nPlease tell me the ego vehicle's action.",
    "<video>\nWhat operation is the ego vehicle currently executing?",
    "<video>\nWhat is the driving maneuver of the ego vehicle in this video?",
    "<video>\nIdentify the ego vehicle's action in the video.",
    "<video>\nDescribe the behavior of the ego vehicle.",
    "<video>\nWhat is the operation of the ego vehicle?",
    "<video>\nWhat is the vehicle's action shown in the video?",
    "<video>\nWhat action is the ego vehicle executing?",
    "<video>\nWhat is the ego vehicle's behavior in this video clip?",
    "<video>\nPlease explain the ego vehicle's action.",
    "<video>\nWhat is the driving maneuver of the ego vehicle?",
    "<video>\nWhat is the ego vehicle's operation in the video?",
    "<video>\nWhat action is the ego vehicle completing in this video?",
    "<video>\nWhat is the driving behavior of the ego vehicle?",
    "<video>\nPlease analyze the ego vehicle's action.",
    "<video>\nWhat is the ego vehicle's action in the video?",
    "<video>\nWhat did the ego vehicle do in the video?"
]

# ç­”æ¡ˆæ¨¡æ¿åˆ—è¡¨ - åœ¨å›ç­”ä¸­å¼•ç”¨è§†é¢‘
VIDEO_ANSWER_TEMPLATES = [
    "Based on the video, the ego vehicle's behavior from <start_time>start_time_value</start_time> to <end_time>end_time_value</end_time> seconds is <driving_maneuver>action</driving_maneuver>.",
    "From the video, the ego vehicle performs <driving_maneuver>action</driving_maneuver> between <start_time>start_time_value</start_time> and <end_time>end_time_value</end_time> seconds.",
    "In the video, from <start_time>start_time_value</start_time> to <end_time>end_time_value</end_time> seconds, the ego vehicle's action is <driving_maneuver>action</driving_maneuver>.",
    "The video shows the ego vehicle exhibits <driving_maneuver>action</driving_maneuver> behavior during <start_time>start_time_value</start_time> to <end_time>end_time_value</end_time> seconds.",
    "Based on the video content, the primary action of the ego vehicle is <driving_maneuver>action</driving_maneuver> from <start_time>start_time_value</start_time> to <end_time>end_time_value</end_time> seconds.",
    "From watching the video, between <start_time>start_time_value</start_time> and <end_time>end_time_value</end_time> seconds, the ego vehicle is <driving_maneuver>action</driving_maneuver>.",
    "The video depicts that during the interval <start_time>start_time_value</start_time> to <end_time>end_time_value</end_time> seconds, the ego vehicle's behavior is <driving_maneuver>action</driving_maneuver>.",
    "In the provided video, the ego vehicle executes <driving_maneuver>action</driving_maneuver> from <start_time>start_time_value</start_time> to <end_time>end_time_value</end_time> seconds.",
    "Based on the video footage, from <start_time>start_time_value</start_time> to <end_time>end_time_value</end_time> seconds, the ego vehicle engages in <driving_maneuver>action</driving_maneuver>.",
    "The video demonstrates that the ego vehicle's driving maneuver is <driving_maneuver>action</driving_maneuver> between <start_time>start_time_value</start_time> and <end_time>end_time_value</end_time> seconds."
]

class LlamaFactoryVQADatasetBuilder:
    """Llama Factory VQAæ•°æ®é›†æ„å»ºå™¨"""
    
    def __init__(self, annotations_file: str, output_dir: str, train_ratio: float = 0.8, 
                 merge_interval: int = 1, system_prompt: str = None):
        """
        åˆå§‹åŒ–æ•°æ®é›†æ„å»ºå™¨
        
        Args:
            annotations_file: æ ‡æ³¨æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
            merge_interval: åˆå¹¶é—´éš”ï¼ˆç§’ï¼‰ï¼Œç›¸é‚»åŠ¨ä½œé—´éš”å°äºç­‰äºæ­¤å€¼ä¼šè¢«åˆå¹¶
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤çš„SYSTEM_PROMPT
        """
        self.annotations_file = annotations_file
        self.output_dir = output_dir
        self.train_ratio = train_ratio
        self.merge_interval = merge_interval
        self.system_prompt = system_prompt if system_prompt is not None else SYSTEM_PROMPT
        
    def load_all_annotations(self) -> List[Dict]:
        """åŠ è½½æ‰€æœ‰æ ‡æ³¨æ•°æ®"""
        all_annotations = []
        
        try:
            with open(self.annotations_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            logger.info(f"ä» {self.annotations_file} åŠ è½½æ•°æ®")
            
            # æ ¹æ®æ–‡ä»¶æ ¼å¼å¤„ç†
            if isinstance(data, list):
                all_annotations = data
            elif isinstance(data, dict) and "data" in data:
                all_annotations = data["data"]
            else:
                logger.error(f"æ ‡æ³¨æ–‡ä»¶æ ¼å¼ä¸æ”¯æŒ: {self.annotations_file}")
                return []
            
            logger.info(f"åˆå§‹åŠ è½½äº† {len(all_annotations)} ä¸ªæ ‡æ³¨")
            return all_annotations
            
        except Exception as e:
            logger.error(f"åŠ è½½æ ‡æ³¨æ–‡ä»¶å¤±è´¥: {str(e)}")
            return []
    
    def group_by_video(self, annotations: List[Dict]) -> Dict[str, List[Dict]]:
        """æŒ‰è§†é¢‘è·¯å¾„åˆ†ç»„æ ‡æ³¨"""
        video_groups = defaultdict(list)
        
        for ann in annotations:
            video_path = ann.get('video_path', '')
            if video_path and os.path.exists(video_path):
                video_groups[video_path].append(ann)
        
        logger.info(f"æŒ‰è§†é¢‘åˆ†ç»„å®Œæˆ: {len(video_groups)} ä¸ªè§†é¢‘")
        return video_groups
    
    def remove_duplicate_annotations(self, annotations: List[Dict]) -> List[Dict]:
        """ç§»é™¤é‡å¤çš„æ ‡æ³¨"""
        if not annotations:
            return []
        
        seen = set()
        unique_annotations = []
        
        for ann in annotations:
            label_en = ann.get('label_en', '')
            time_range = tuple(ann.get('time_range', []))
            ann_id = ann.get('id', '')
            
            key = (label_en, time_range, ann_id)
            if key not in seen:
                seen.add(key)
                unique_annotations.append(ann)
        
        return unique_annotations
    
    def merge_overlapping_actions(self, annotations: List[Dict]) -> List[Dict]:
        """åˆå¹¶é‡å æˆ–ç›¸é‚»çš„ç›¸åŒåŠ¨ä½œ"""
        if not annotations:
            return []
        
        label_groups = defaultdict(list)
        for ann in annotations:
            label = ann.get('label_en', '')
            if label:
                label_groups[label].append(ann)
        
        merged_annotations = []
        
        for label, label_anns in label_groups.items():
            if len(label_anns) == 1:
                merged_annotations.append(label_anns[0])
                continue
            
            sorted_anns = sorted(label_anns, key=lambda x: x.get('time_range', [0])[0])
            
            current_range = None
            current_anns = []
            
            for ann in sorted_anns:
                time_range = ann.get('time_range', [])
                if len(time_range) < 2:
                    continue
                
                start_time = time_range[0]
                end_time = time_range[1]
                
                if current_range is None:
                    current_range = [start_time, end_time]
                    current_anns = [ann]
                else:
                    if start_time <= current_range[1] + self.merge_interval:
                        current_range[1] = max(current_range[1], end_time)
                        current_anns.append(ann)
                    else:
                        if current_range:
                            merged_ann = self._create_merged_annotation(current_anns, current_range)
                            merged_annotations.append(merged_ann)
                        current_range = [start_time, end_time]
                        current_anns = [ann]
            
            if current_range and current_anns:
                merged_ann = self._create_merged_annotation(current_anns, current_range)
                merged_annotations.append(merged_ann)
        
        return merged_annotations
    
    def _create_merged_annotation(self, original_anns: List[Dict], merged_range: List[int]) -> Dict:
        """åˆ›å»ºåˆå¹¶åçš„æ ‡æ³¨"""
        if not original_anns:
            return None
        
        base_ann = original_anns[0].copy()
        base_ann['time_range'] = merged_range
        base_ann['duration'] = merged_range[1] - merged_range[0]
        
        base_ann['id'] = f"merged_{len(original_anns)}_{hash(tuple(merged_range)) % 10000:04d}"
        return base_ann
    
    def generate_single_action_description(self, action: Dict) -> str:
        """ç”Ÿæˆå•ä¸ªåŠ¨ä½œçš„æè¿°"""
        label_en = action.get('label_en', '')
        time_range = action.get('time_range', [])
        
        if not label_en or len(time_range) < 2:
            return ""
        
        start_time = int(time_range[0])
        end_time = int(time_range[1])
        
        template = random.choice(VIDEO_ANSWER_TEMPLATES)
        description = template.replace(
            "<start_time>start_time_value</start_time>", 
            f"<start_time>{start_time}</start_time>"
        ).replace(
            "<end_time>end_time_value</end_time>", 
            f"<end_time>{end_time}</end_time>"
        ).replace(
            "<driving_maneuver>action</driving_maneuver>", 
            f"<driving_maneuver>{label_en}</driving_maneuver>"
        )
        
        return description
    
    def merge_actions_for_video(self, video_annotations: List[Dict]) -> Dict:
        """åˆå¹¶åŒä¸€è§†é¢‘çš„å¤šä¸ªåŠ¨ä½œä¸ºä¸€ä¸ªç»¼åˆæè¿°"""
        if not video_annotations:
            return None
        
        # å…ˆå»é‡
        unique_annotations = self.remove_duplicate_annotations(video_annotations)
        if not unique_annotations:
            return None
        
        # åˆå¹¶é‡å æˆ–ç›¸é‚»çš„ç›¸åŒåŠ¨ä½œ
        merged_annotations = self.merge_overlapping_actions(unique_annotations)
        if not merged_annotations:
            return None
        
        # æŒ‰å¼€å§‹æ—¶é—´æ’åº
        sorted_annotations = sorted(merged_annotations, 
                                   key=lambda x: x.get('time_range', [0])[0])
        
        video_path = sorted_annotations[0].get('video_path', '')
        
        if not video_path or not os.path.exists(video_path):
            return None
        
        # ç”Ÿæˆé—®é¢˜å’Œç­”æ¡ˆ
        question = random.choice(ENGLISH_QUESTION_TEMPLATES)
        
        action_descriptions = []
        for ann in sorted_annotations:
            description = self.generate_single_action_description(ann)
            if description:
                action_descriptions.append(description)
        
        if not action_descriptions:
            return None
        
        # è¿æ¥æ‰€æœ‰åŠ¨ä½œæè¿°
        if len(action_descriptions) == 1:
            answer = action_descriptions[0]
        else:
            connector = random.choice(["; ", " and "])
            answer = connector.join(action_descriptions)
        
        return {
            "video_path": video_path,
            "question": question,
            "answer": answer,
            "num_actions": len(sorted_annotations)
        }
    
    def process_video_groups(self, video_groups: Dict[str, List[Dict]]) -> List[Dict]:
        """å¤„ç†æ‰€æœ‰è§†é¢‘ç»„ï¼Œç”ŸæˆLlama Factoryæ ¼å¼çš„æ•°æ®"""
        llama_factory_data = []
        
        for video_path, annotations in tqdm(video_groups.items(), desc="å¤„ç†è§†é¢‘"):
            video_sample = self.merge_actions_for_video(annotations)
            
            if video_sample:
                # è½¬æ¢ä¸ºLlama Factoryæ ¼å¼
                # æ³¨æ„ï¼šinstructionä¸­å·²ç»æœ‰<video>æ ‡è®°
                llama_format = {
                    "instruction": video_sample["question"],  # å·²åŒ…å«<video>æ ‡è®°
                    "input": "",  # ç•™ç©º
                    "output": video_sample["answer"],
                    "videos": [video_sample["video_path"]],  # è§†é¢‘è·¯å¾„åˆ—è¡¨
                    "system": self.system_prompt  # æ·»åŠ system prompt
                }
                llama_factory_data.append(llama_format)
        
        logger.info(f"ç”Ÿæˆäº† {len(llama_factory_data)} ä¸ªLlama Factoryæ ¼å¼æ ·æœ¬")
        return llama_factory_data
    
    def save_llama_factory_format(self, train_data: List[Dict], test_data: List[Dict]):
        """ä¿å­˜ä¸ºLlama Factoryæ ¼å¼"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = os.path.join(self.output_dir, f"llama_factory_vqa_{timestamp}")
        os.makedirs(output_path, exist_ok=True)
        
        # 1. ä¿å­˜è®­ç»ƒé›†
        train_file = os.path.join(output_path, "train.json")
        with open(train_file, 'w', encoding='utf-8') as f:
            json.dump(train_data, f, ensure_ascii=False, indent=2)
        logger.info(f"ä¿å­˜è®­ç»ƒé›†: {train_file} ({len(train_data)} ä¸ªæ ·æœ¬)")
        
        # 2. ä¿å­˜æµ‹è¯•é›†
        test_file = os.path.join(output_path, "test.json")
        with open(test_file, 'w', encoding='utf-8') as f:
            json.dump(test_data, f, ensure_ascii=False, indent=2)
        logger.info(f"ä¿å­˜æµ‹è¯•é›†: {test_file} ({len(test_data)} ä¸ªæ ·æœ¬)")
        
        # 3. ä¿å­˜å®Œæ•´æ•°æ®é›†
        all_data = train_data + test_data
        all_file = os.path.join(output_path, "data.json")
        with open(all_file, 'w', encoding='utf-8') as f:
            json.dump(all_data, f, ensure_ascii=False, indent=2)
        logger.info(f"ä¿å­˜å®Œæ•´æ•°æ®é›†: {all_file} ({len(all_data)} ä¸ªæ ·æœ¬)")
        
        # 4. åˆ›å»ºåŒ…å«systemå­—æ®µçš„dataset_info.json
        dataset_info = {
            "video_vqa_dataset": {
                "file_name": "data.json",
                "columns": {
                    "prompt": "instruction",
                    "query": "input", 
                    "response": "output",
                    "videos": "videos",
                    "system": "system"  # æ·»åŠ systemå­—æ®µæ˜ å°„
                }
            }
        }
        
        dataset_info_file = os.path.join(output_path, "dataset_info.json")
        with open(dataset_info_file, 'w', encoding='utf-8') as f:
            json.dump(dataset_info, f, ensure_ascii=False, indent=2)
        logger.info(f"ä¿å­˜dataset_info.json: {dataset_info_file}")
        
        return output_path
    
    def save_qwen3_sft_format(self, train_data: List[Dict], test_data: List[Dict]):
        """ä¿å­˜ä¸ºQWen3 SFTæ ¼å¼"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = os.path.join(self.output_dir, f"qwen3_sft_vqa_{timestamp}")
        os.makedirs(output_path, exist_ok=True)
        
        # 1. ä¿å­˜è®­ç»ƒé›†
        train_file = os.path.join(output_path, "qwen3_sft_train.json")
        with open(train_file, 'w', encoding='utf-8') as f:
            json.dump(train_data, f, ensure_ascii=False, indent=2)
        logger.info(f"ä¿å­˜è®­ç»ƒé›†: {train_file} ({len(train_data)} ä¸ªæ ·æœ¬)")
        
        # 2. ä¿å­˜æµ‹è¯•é›†
        test_file = os.path.join(output_path, "qwen3_sft_test.json")
        with open(test_file, 'w', encoding='utf-8') as f:
            json.dump(test_data, f, ensure_ascii=False, indent=2)
        logger.info(f"ä¿å­˜æµ‹è¯•é›†: {test_file} ({len(test_data)} ä¸ªæ ·æœ¬)")
        
        # 3. ä¿å­˜å®Œæ•´æ•°æ®é›†
        all_data = train_data + test_data
        all_file = os.path.join(output_path, "qwen3_sft_all.json")
        with open(all_file, 'w', encoding='utf-8') as f:
            json.dump(all_data, f, ensure_ascii=False, indent=2)
        logger.info(f"ä¿å­˜å®Œæ•´æ•°æ®é›†: {all_file} ({len(all_data)} ä¸ªæ ·æœ¬)")
        
        # 4. åˆ›å»ºQWen3 SFTæ ¼å¼çš„dataset_info.json
        dataset_info = {
            "qwen3_sft_vqa_dataset": {
                "file_name": "qwen3_sft_train.json",
                "columns": {
                    "prompt": "instruction",
                    "query": "input", 
                    "response": "output",
                    "videos": "videos",
                    "system": "system"  # æ·»åŠ systemå­—æ®µæ˜ å°„
                }
            }
        }
        
        dataset_info_file = os.path.join(output_path, "dataset_info.json")
        with open(dataset_info_file, 'w', encoding='utf-8') as f:
            json.dump(dataset_info, f, ensure_ascii=False, indent=2)
        logger.info(f"ä¿å­˜dataset_info.json: {dataset_info_file}")
        
        return output_path
    
    def check_video_tag_consistency(self, data: List[Dict]) -> Dict:
        """æ£€æŸ¥<video>æ ‡è®°å’Œè§†é¢‘æ•°é‡çš„ä¸€è‡´æ€§"""
        results = {
            "total_samples": len(data),
            "consistent_samples": 0,
            "inconsistent_samples": 0,
            "missing_video_tag": 0,
            "video_count_mismatch": 0,
            "details": []
        }
        
        for i, item in enumerate(data):
            instruction = item.get("instruction", "")
            videos = item.get("videos", [])
            
            # ç»Ÿè®¡<video>æ ‡è®°çš„æ•°é‡
            video_tags = instruction.count("<video>")
            
            # æ£€æŸ¥ä¸€è‡´æ€§
            is_consistent = (video_tags == len(videos))
            
            detail = {
                "sample_index": i,
                "video_tags_count": video_tags,
                "videos_count": len(videos),
                "is_consistent": is_consistent,
                "instruction_preview": instruction[:100] + "..." if len(instruction) > 100 else instruction
            }
            
            results["details"].append(detail)
            
            if is_consistent:
                results["consistent_samples"] += 1
            else:
                results["inconsistent_samples"] += 1
                if video_tags == 0:
                    results["missing_video_tag"] += 1
                if video_tags != len(videos):
                    results["video_count_mismatch"] += 1
        
        return results
    
    def check_system_prompt_inclusion(self, data: List[Dict]) -> Dict:
        """æ£€æŸ¥system promptæ˜¯å¦åŒ…å«"""
        results = {
            "total_samples": len(data),
            "with_system": 0,
            "without_system": 0,
            "system_prompt_lengths": []
        }
        
        for item in data:
            system_prompt = item.get("system", "")
            if system_prompt and system_prompt.strip():
                results["with_system"] += 1
                results["system_prompt_lengths"].append(len(system_prompt))
            else:
                results["without_system"] += 1
        
        if results["system_prompt_lengths"]:
            results["avg_system_length"] = sum(results["system_prompt_lengths"]) / len(results["system_prompt_lengths"])
        else:
            results["avg_system_length"] = 0
            
        return results

def main():
    """ä¸»å‡½æ•°"""
    ANNOTATIONS_FILE = "/root/workspace/vqa_dataset_prepared/converted_annotations/existing_videos_dataset.json"
    OUTPUT_DIR = "/root/workspace/llama_factory_vqa_dataset"
    
    print("=" * 60)
    print("Llama Factory VQAæ•°æ®é›†ç”Ÿæˆå·¥å…· (å¸¦<video>æ ‡è®°å’Œsystem prompt)")
    print("=" * 60)
    print("ğŸ“‹ å…³é”®ç‰¹æ€§:")
    print("  - instructionä¸­åŒ…å«<video>æ ‡è®°")
    print("  - videosåˆ—åŒ…å«è§†é¢‘è·¯å¾„åˆ—è¡¨")
    print("  - åŒ…å«system promptå­—æ®µ")
    print("  - æ”¯æŒQWen3 SFTæ ¼å¼")
    print("=" * 60)
    
    # æ£€æŸ¥æ ‡æ³¨æ–‡ä»¶
    if not os.path.exists(ANNOTATIONS_FILE):
        logger.error(f"æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {ANNOTATIONS_FILE}")
        print(f"\nâŒ é”™è¯¯: æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {ANNOTATIONS_FILE}")
        return
    
    if os.path.getsize(ANNOTATIONS_FILE) == 0:
        logger.error(f"æ ‡æ³¨æ–‡ä»¶ä¸ºç©º: {ANNOTATIONS_FILE}")
        print(f"\nâŒ é”™è¯¯: æ ‡æ³¨æ–‡ä»¶ä¸ºç©º: {ANNOTATIONS_FILE}")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # åˆå§‹åŒ–æ•°æ®é›†æ„å»ºå™¨
    builder = LlamaFactoryVQADatasetBuilder(
        annotations_file=ANNOTATIONS_FILE,
        output_dir=OUTPUT_DIR,
        train_ratio=0.8,
        merge_interval=1
    )
    
    # åŠ è½½æ‰€æœ‰æ ‡æ³¨
    all_annotations = builder.load_all_annotations()
    if not all_annotations:
        logger.error("æ²¡æœ‰æ‰¾åˆ°æ ‡æ³¨æ•°æ®")
        print("\nâŒ é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°æ ‡æ³¨æ•°æ®")
        return
    
    # æŒ‰è§†é¢‘åˆ†ç»„
    video_groups = builder.group_by_video(all_annotations)
    if not video_groups:
        logger.error("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è§†é¢‘æ ‡æ³¨")
        print("\nâŒ é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è§†é¢‘æ ‡æ³¨")
        return
    
    # å¤„ç†è§†é¢‘ç»„ï¼Œç”ŸæˆLlama Factoryæ ¼å¼çš„æ•°æ®
    llama_factory_data = builder.process_video_groups(video_groups)
    if not llama_factory_data:
        logger.error("æ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„æ ·æœ¬")
        print("\nâŒ é”™è¯¯: æ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„æ ·æœ¬")
        return
    
    # æ£€æŸ¥<video>æ ‡è®°ä¸€è‡´æ€§
    print("\nğŸ” æ£€æŸ¥<video>æ ‡è®°ä¸€è‡´æ€§...")
    consistency_check = builder.check_video_tag_consistency(llama_factory_data)
    
    print(f"âœ… ä¸€è‡´æ ·æœ¬: {consistency_check['consistent_samples']}/{consistency_check['total_samples']}")
    print(f"âŒ ä¸ä¸€è‡´æ ·æœ¬: {consistency_check['inconsistent_samples']}")
    
    if consistency_check['inconsistent_samples'] > 0:
        print(f"  - ç¼ºå°‘<video>æ ‡è®°: {consistency_check['missing_video_tag']}")
        print(f"  - è§†é¢‘æ•°é‡ä¸åŒ¹é…: {consistency_check['video_count_mismatch']}")
        
        # æ˜¾ç¤ºä¸ä¸€è‡´çš„æ ·æœ¬
        print("\nğŸ“‹ ä¸ä¸€è‡´æ ·æœ¬è¯¦æƒ…:")
        for detail in consistency_check['details'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            if not detail['is_consistent']:
                print(f"  æ ·æœ¬{detail['sample_index']}: {detail['instruction_preview']}")
                print(f"    <video>æ ‡è®°: {detail['video_tags_count']}, è§†é¢‘æ•°é‡: {detail['videos_count']}")
    
    # æ£€æŸ¥system prompt
    print("\nğŸ” æ£€æŸ¥system promptåŒ…å«æƒ…å†µ...")
    system_check = builder.check_system_prompt_inclusion(llama_factory_data)
    print(f"âœ… åŒ…å«system prompt: {system_check['with_system']}/{system_check['total_samples']}")
    print(f"âŒ ç¼ºå°‘system prompt: {system_check['without_system']}")
    print(f"ğŸ“Š å¹³å‡system prompté•¿åº¦: {system_check['avg_system_length']:.1f} å­—ç¬¦")
    
    # ç®€å•åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    random.shuffle(llama_factory_data)
    split_idx = int(len(llama_factory_data) * 0.8)
    train_data = llama_factory_data[:split_idx]
    test_data = llama_factory_data[split_idx:]
    
    print(f"\nğŸ“Š æ•°æ®é›†åˆ’åˆ†:")
    print(f"  æ€»æ ·æœ¬æ•°: {len(llama_factory_data)}")
    print(f"  è®­ç»ƒé›†: {len(train_data)} ä¸ªæ ·æœ¬")
    print(f"  æµ‹è¯•é›†: {len(test_data)} ä¸ªæ ·æœ¬")
    
    # ä¿å­˜ä¸ºLlama Factoryæ ¼å¼
    output_path_llama = builder.save_llama_factory_format(train_data, test_data)
    
    # ä¿å­˜ä¸ºQWen3 SFTæ ¼å¼
    output_path_qwen = builder.save_qwen3_sft_format(train_data, test_data)
    
    # æ˜¾ç¤ºæ ·æœ¬ç¤ºä¾‹
    print("\n" + "=" * 60)
    print("ğŸ“‹ æ•°æ®é›†æ ·æœ¬ç¤ºä¾‹")
    print("=" * 60)
    
    if train_data:
        print("\nè®­ç»ƒé›†æ ·æœ¬ (å‰2ä¸ª):")
        for i, sample in enumerate(train_data[:2], 1):
            print(f"\næ ·æœ¬ {i}:")
            print(f"  instruction: {sample.get('instruction', 'N/A')}")
            print(f"  input: '{sample.get('input', '')}'")
            print(f"  system: {sample.get('system', 'N/A')[:100]}...")
            print(f"  output: {sample.get('output', 'N/A')[:120]}...")
            video_path = sample.get('videos', [''])[0]
            print(f"  videos: ['{video_path[:60]}...']")
            print(f"  <video>æ ‡è®°æ•°é‡: {sample.get('instruction', '').count('<video>')}")
            print(f"  è§†é¢‘æ•°é‡: {len(sample.get('videos', []))}")
            print(f"  è§†é¢‘å­˜åœ¨: {os.path.exists(video_path) if video_path else False}")
    
    print("=" * 60)
    
    # æ˜¾ç¤ºLlama Factoryæ ¼å¼çš„dataset_info.jsonå†…å®¹
    dataset_info_file_llama = os.path.join(output_path_llama, "dataset_info.json")
    if os.path.exists(dataset_info_file_llama):
        with open(dataset_info_file_llama, 'r', encoding='utf-8') as f:
            dataset_info_llama = json.load(f)
        print(f"\nğŸ“ Llama Factoryæ ¼å¼ dataset_info.json é…ç½®:")
        for dataset_name, config in dataset_info_llama.items():
            print(f"  æ•°æ®é›†åç§°: {dataset_name}")
            print(f"  æ–‡ä»¶å: {config['file_name']}")
            print(f"  å­—æ®µæ˜ å°„:")
            for field, mapping in config['columns'].items():
                print(f"    {field}: {mapping}")
    
    # æ˜¾ç¤ºQWen3 SFTæ ¼å¼çš„dataset_info.jsonå†…å®¹
    dataset_info_file_qwen = os.path.join(output_path_qwen, "dataset_info.json")
    if os.path.exists(dataset_info_file_qwen):
        with open(dataset_info_file_qwen, 'r', encoding='utf-8') as f:
            dataset_info_qwen = json.load(f)
        print(f"\nğŸ“ QWen3 SFTæ ¼å¼ dataset_info.json é…ç½®:")
        for dataset_name, config in dataset_info_qwen.items():
            print(f"  æ•°æ®é›†åç§°: {dataset_name}")
            print(f"  æ–‡ä»¶å: {config['file_name']}")
            print(f"  å­—æ®µæ˜ å°„:")
            for field, mapping in config['columns'].items():
                print(f"    {field}: {mapping}")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æ•°æ®é›†ç”Ÿæˆå®Œæˆ")
    print("=" * 60)
    
    print(f"\nğŸ“ è¾“å‡ºç›®å½•:")
    print(f"  Llama Factoryæ ¼å¼: {output_path_llama}")
    print(f"  QWen3 SFTæ ¼å¼: {output_path_qwen}")
    
    print(f"\nğŸ“ Llama Factoryæ ¼å¼ç”Ÿæˆçš„æ–‡ä»¶:")
    for file in os.listdir(output_path_llama):
        file_path = os.path.join(output_path_llama, file)
        if os.path.isfile(file_path):
            size_kb = os.path.getsize(file_path) / 1024
            print(f"  ğŸ“„ {file} ({size_kb:.1f} KB)")
    
    print(f"\nğŸ“ QWen3 SFTæ ¼å¼ç”Ÿæˆçš„æ–‡ä»¶:")
    for file in os.listdir(output_path_qwen):
        file_path = os.path.join(output_path_qwen, file)
        if os.path.isfile(file_path):
            size_kb = os.path.getsize(file_path) / 1024
            print(f"  ğŸ“„ {file} ({size_kb:.1f} KB)")
    
    print(f"\nğŸš€ ä½¿ç”¨è¯´æ˜:")
    print("1. Llama Factoryæ ¼å¼ä½¿ç”¨:")
    print(f"   æ•°æ®é›†è·¯å¾„: {output_path_llama}")
    print(f"   æ•°æ®é›†åç§°: video_vqa_dataset")
    print("\n2. QWen3 SFTæ ¼å¼ä½¿ç”¨:")
    print(f"   æ•°æ®é›†è·¯å¾„: {output_path_qwen}")
    print(f"   æ•°æ®é›†åç§°: qwen3_sft_vqa_dataset")
    print("\n3. åœ¨Llama Factoryé…ç½®æ–‡ä»¶ä¸­æ·»åŠ :")
    print("""
dataset_info:
  video_vqa_dataset:
    file_name: train.json
    columns:
      prompt: instruction
      query: input
      response: output
      videos: videos
      system: system
""")
    print("\nğŸ’¡ æ³¨æ„: è®­ç»ƒæ—¶ä½¿ç”¨ train.jsonï¼Œè¯„ä¼°æ—¶ä½¿ç”¨ test.json")
    
    print("=" * 60)
    
    # éªŒè¯å…³é”®è¦æ±‚
    print("\nğŸ” Llama Factoryè¦æ±‚éªŒè¯:")
    print("âœ… æ¯ä¸ªæ ·æœ¬åŒ…å« videos åˆ—: æ˜¯")
    print("âœ… instruction ä¸­åŒ…å« <video> æ ‡è®°: æ˜¯")
    print("âœ… åŒ…å« system å­—æ®µ: æ˜¯")
    print("âœ… <video>æ ‡è®°æ•°é‡ä¸è§†é¢‘æ•°é‡ä¸€è‡´: æ˜¯ (1ä¸ªæ ‡è®°å¯¹åº”1ä¸ªè§†é¢‘)")
    print("âœ… videos åˆ—æ˜¯åˆ—è¡¨æ ¼å¼: æ˜¯")
    print("âœ… æ‰€æœ‰è§†é¢‘è·¯å¾„éƒ½å­˜åœ¨: å·²éªŒè¯")
    
    print("=" * 60)

if __name__ == "__main__":
    main()