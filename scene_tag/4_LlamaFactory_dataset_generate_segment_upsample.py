import os
import json
import random
import copy  # <--- æ–°å¢ï¼šç”¨äºæ·±æ‹·è´
from typing import Dict, List, Tuple, Optional  
import logging
from datetime import datetime
from tqdm import tqdm
from collections import defaultdict, Counter # <--- æ–°å¢ï¼šç”¨äºç»Ÿè®¡

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/root/workspace/llama_factory_dataset_generation.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ç±»åˆ«å®šä¹‰ - å¯ç‹¬ç«‹æ‰©å±•çš„éƒ¨åˆ†
DRIVING_MANEUVER_CATEGORIES = {
    "TrafficLight_StraightStopOrGo": "Ego vehicle stops or starts at a traffic light for straight-line movement",
    "TrafficLight_LeftTurnStopOrGo": "Ego vehicle stops or starts at a traffic light for left-turn movement",
    "LaneChange_NavForIntersection": "Lane change for navigation purposes approaching an intersection",
    "LaneChange_AvoidSlowVRU": "Lane change to avoid slow-moving vulnerable road users (pedestrians, cyclists)",
    "LaneChange_AvoidStaticVehicle": "Lane change to avoid stationary vehicles",
    "DynamicInteraction_VRUInLaneCrossing": "Interaction with vulnerable road users crossing the ego's lane",
    "DynamicInteraction_VehicleInLaneCrossing": "Interaction with other vehicles crossing the ego's lane",
    "DynamicInteraction_StandardVehicleCutIn": "Another vehicle cuts in front of the ego vehicle",
    "StartStop_StartFromMainRoad": "Starting from a stopped position on a main road",
    "StartStop_ParkRoadside": "Parking or stopping at roadside",
    "Intersection_StandardUTurn": "Making a U-turn at an intersection",
    "LaneCruising_Straight": "Straight-line cruising without notable events"
}

# è·å–ç±»åˆ«åˆ—è¡¨
CATEGORY_LABELS = list(DRIVING_MANEUVER_CATEGORIES.keys())
CATEGORY_LIST_STR = "\n".join(CATEGORY_LABELS)

# ç”Ÿæˆç±»åˆ«å®šä¹‰çš„æ–‡æœ¬
CATEGORY_DEFINITIONS = "\n".join(
    [f"{i+1}. {label}: {definition}" 
     for i, (label, definition) in enumerate(DRIVING_MANEUVER_CATEGORIES.items())]
)

# ä¸»ç³»ç»Ÿæç¤º - ä¿®æ”¹ä¸º20ç§’åˆ‡ç‰‡è§†é¢‘
SYSTEM_PROMPT = f"""You are an expert in autonomous driving scene annotation.
Based on the input video and the question about the ego vehicle's behavior, analyze the 20-second video to identify the ego vehicle's actions with strict precision, focusing on predefined driving maneuver categories.

DRIVING MANEUVER CATEGORIES:
You MUST use ONLY these predefined labels for the ego vehicle's actions:

{CATEGORY_LIST_STR}
else (ONLY when NO label above matches, meaning the ego vehicle's action does not fit any of the predefined categories)

LABELING RULES:
1. Assign a label ONLY if the action clearly matches the definition of one of the predefined categories
2. NEVER force-match ambiguous scenes to predefined labels
3. Use "else" when:
   â€¢ The ego vehicle's action does not match any predefined category
   â€¢ The scene is ambiguous or uncertain (confidence < 90%)
   â€¢ No clearly identifiable maneuver occurs
4. For "else" segments: Cover ONLY time periods with NO identifiable predefined maneuver
5. Time segments MUST be contiguous
6. Minimum segment duration: 1.0 second. Ignore shorter or transient actions
7. Base times on video timeline (0 to 20 seconds)

OUTPUT FORMAT:
<driving_maneuver>action_label</driving_maneuver> from <start_time>XX</start_time> to <end_time>YY</end_time> seconds
â€¢ Use one of the predefined category labels or "else" for each time segment
â€¢ Time precision: 0 decimal places (e.g., 5, 23)
â€¢ NO additional text or explanationsâ€”only output the formatted segments

CATEGORY DEFINITIONS:
{CATEGORY_DEFINITIONS}
13. else: Default for all other behaviors not covered by the predefined categories

IMPORTANT GUIDELINES:
1. Analyze the entire 20-second video thoroughly
2. Match actions to the most specific appropriate category
3. If multiple categories could apply, choose the one that best describes the primary action
4. Ensure time segments accurately reflect when each maneuver occurs
5. Maintain chronological order in output
"""


# é—®é¢˜æ¨¡æ¿åˆ—è¡¨ - åœ¨è§†é¢‘å‰æ·»åŠ <video>æ ‡è®°
ENGLISH_QUESTION_TEMPLATES = [
    "<video>\nWhat is the ego vehicle's action in this 20-second video clip?",
    "<video>\nWhat is the ego vehicle doing in this 20-second video?",
    "<video>\nWhat is the behavior of the ego vehicle in this 20-second clip?",
    "<video>\nPlease tell me the ego vehicle's action in this 20-second video.",
    "<video>\nWhat operation is the ego vehicle currently executing in this 20-second clip?",
    "<video>\nWhat is the driving maneuver of the ego vehicle in this 20-second video?",
    "<video>\nIdentify the ego vehicle's action in this 20-second video clip.",
    "<video>\nDescribe the behavior of the ego vehicle in this 20-second video.",
    "<video>\nWhat is the operation of the ego vehicle in this 20-second clip?",
    "<video>\nWhat is the vehicle's action shown in this 20-second video?",
    "<video>\nWhat action is the ego vehicle executing in this 20-second clip?",
    "<video>\nWhat is the ego vehicle's behavior in this 20-second video?",
    "<video>\nPlease explain the ego vehicle's action in this 20-second video.",
    "<video>\nWhat is the driving maneuver of the ego vehicle in this 20-second clip?",
    "<video>\nWhat is the ego vehicle's operation in this 20-second video?",
    "<video>\nWhat action is the ego vehicle completing in this 20-second video?",
    "<video>\nWhat is the driving behavior of the ego vehicle in this 20-second clip?",
    "<video>\nPlease analyze the ego vehicle's action in this 20-second video.",
    "<video>\nWhat is the ego vehicle's action in this 20-second video clip?",
    "<video>\nWhat did the ego vehicle do in this 20-second video?"
]

# ç­”æ¡ˆæ¨¡æ¿åˆ—è¡¨ - åœ¨å›ç­”ä¸­å¼•ç”¨è§†é¢‘
VIDEO_ANSWER_TEMPLATES = [
    "Based on the 20-second video, the ego vehicle's behavior from <start_time>start_time_value</start_time> to <end_time>end_time_value</end_time> seconds is <driving_maneuver>action</driving_maneuver>.",
    "From the 20-second video, the ego vehicle performs <driving_maneuver>action</driving_maneuver> between <start_time>start_time_value</start_time> and <end_time>end_time_value</end_time> seconds.",
    "In this 20-second video, from <start_time>start_time_value</start_time> to <end_time>end_time_value</end_time> seconds, the ego vehicle's action is <driving_maneuver>action</driving_maneuver>.",
    "The 20-second video shows the ego vehicle exhibits <driving_maneuver>action</driving_maneuver> behavior during <start_time>start_time_value</start_time> to <end_time>end_time_value</end_time> seconds.",
    "Based on the 20-second video content, the primary action of the ego vehicle is <driving_maneuver>action</driving_maneuver> from <start_time>start_time_value</start_time> to <end_time>end_time_value</end_time> seconds.",
    "From watching this 20-second video, between <start_time>start_time_value</start_time> and <end_time>end_time_value</end_time> seconds, the ego vehicle is <driving_maneuver>action</driving_maneuver>.",
    "The 20-second video depicts that during the interval <start_time>start_time_value</start_time> to <end_time>end_time_value</end_time> seconds, the ego vehicle's behavior is <driving_maneuver>action</driving_maneuver>.",
    "In this 20-second video, the ego vehicle executes <driving_maneuver>action</driving_maneuver> from <start_time>start_time_value</start_time> to <end_time>end_time_value</end_time> seconds.",
    "Based on the 20-second video footage, from <start_time>start_time_value</start_time> to <end_time>end_time_value</end_time> seconds, the ego vehicle engages in <driving_maneuver>action</driving_maneuver>.",
    "The 20-second video demonstrates that the ego vehicle's driving maneuver is <driving_maneuver>action</driving_maneuver> between <start_time>start_time_value</start_time> and <end_time>end_time_value</end_time> seconds."
]

class LlamaFactoryVQADatasetBuilder:
    """Llama Factory VQAæ•°æ®é›†æ„å»ºå™¨"""
    
    def __init__(self, annotations_file: str, output_dir: str, train_ratio: float = 0.8, 
                 system_prompt: str = None):
        """åˆå§‹åŒ–æ•°æ®é›†æ„å»ºå™¨"""
        self.annotations_file = annotations_file
        self.output_dir = output_dir
        self.train_ratio = train_ratio
        self.system_prompt = system_prompt if system_prompt is not None else SYSTEM_PROMPT
        
    def load_all_annotations(self) -> List[Dict]:
        """åŠ è½½æ‰€æœ‰æ ‡æ³¨æ•°æ®"""
        all_annotations = []
        
        try:
            with open(self.annotations_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            logger.info(f"ä» {self.annotations_file} åŠ è½½æ•°æ®")
            
            # æ ¹æ®æ–‡ä»¶æ ¼å¼å¤„ç†
            if isinstance(data, list):
                all_annotations = data
            elif isinstance(data, dict) and "data" in data:
                all_annotations = data["data"]
            else:
                logger.error(f"æ ‡æ³¨æ–‡ä»¶æ ¼å¼ä¸æ”¯æŒ: {self.annotations_file}")
                return []
            
            logger.info(f"åˆå§‹åŠ è½½äº† {len(all_annotations)} ä¸ªæ ‡æ³¨")
            return all_annotations
            
        except Exception as e:
            logger.error(f"åŠ è½½æ ‡æ³¨æ–‡ä»¶å¤±è´¥: {str(e)}")
            return []
    
    def remove_duplicate_annotations(self, annotations: List[Dict]) -> List[Dict]:
        """ç§»é™¤é‡å¤çš„æ ‡æ³¨"""
        if not annotations:
            return []
        
        seen = set()
        unique_annotations = []
        
        for ann in annotations:
            video_path = ann.get('video_path', '')
            time_range = tuple(ann.get('time_range_in_slice', []))
            label_en = ann.get('label_en', '')
            
            # åªæœ‰å½“è§†é¢‘ã€æ—¶é—´ã€æ ‡ç­¾å®Œå…¨ä¸€è‡´æ—¶æ‰è®¤ä¸ºæ˜¯é‡å¤
            key = (video_path, time_range, label_en)
            if key not in seen:
                seen.add(key)
                unique_annotations.append(ann)
        
        return unique_annotations
    
    def generate_single_action_description(self, action: Dict) -> str:
        """ç”Ÿæˆå•ä¸ªåŠ¨ä½œçš„æè¿°"""
        label_en = action.get('label_en', '')
        time_range = action.get('time_range_in_slice', [])
        
        if not label_en or len(time_range) < 2:
            return ""
        
        start_time = time_range[0]
        end_time = time_range[1]
        
        # ç¡®ä¿æ—¶é—´åœ¨0-20ç§’èŒƒå›´å†…
        if start_time < 0:
            start_time = 0
        if end_time > 20:
            end_time = 20
        
        template = random.choice(VIDEO_ANSWER_TEMPLATES)
        description = template.replace(
            "<start_time>start_time_value</start_time>", 
            f"<start_time>{start_time:.1f}</start_time>"
        ).replace(
            "<end_time>end_time_value</end_time>", 
            f"<end_time>{end_time:.1f}</end_time>"
        ).replace(
            "<driving_maneuver>action</driving_maneuver>", 
            f"<driving_maneuver>{label_en}</driving_maneuver>"
        )
        
        return description
    
    def process_single_sliced_annotation(self, annotation: Dict) -> Optional[Dict]:
        """å¤„ç†å•ä¸ªåˆ‡ç‰‡æ ‡æ³¨ç”Ÿæˆæ ·æœ¬"""
        try:
            # è·å–å¿…è¦ä¿¡æ¯
            video_path = annotation.get('video_path', '')
            label_en = annotation.get('label_en', '')
            time_range = annotation.get('time_range_in_slice', [])
            
            # éªŒè¯æ•°æ®
            if not video_path or not os.path.exists(video_path):
                logger.warning(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
                return None
            
            if not label_en:
                logger.warning(f"ç¼ºå°‘è‹±æ–‡æ ‡ç­¾: {annotation.get('id', 'unknown')}")
                return None
            
            if len(time_range) < 2:
                logger.warning(f"æ— æ•ˆçš„æ—¶é—´èŒƒå›´: {annotation.get('id', 'unknown')}")
                return None
            
            # ç”Ÿæˆé—®é¢˜å’Œç­”æ¡ˆ
            question = random.choice(ENGLISH_QUESTION_TEMPLATES)
            answer = self.generate_single_action_description(annotation)
            
            if not answer:
                logger.warning(f"æ— æ³•ç”Ÿæˆç­”æ¡ˆ: {annotation.get('id', 'unknown')}")
                return None
            
            # è½¬æ¢ä¸ºLlama Factoryæ ¼å¼
            return {
                "instruction": question,
                "input": "",  # ç•™ç©º
                "output": answer,
                "videos": [video_path],  # è§†é¢‘è·¯å¾„åˆ—è¡¨
                "system": self.system_prompt,  # æ·»åŠ system prompt
                "slice_key": annotation.get('slice_key', ''),
                "time_range_in_slice": time_range,
                "label_en": label_en # <--- ä¿ç•™è¿™ä¸ªå­—æ®µï¼Œåç»­ç”¨äºä¸Šé‡‡æ ·ç»Ÿè®¡
            }
            
        except Exception as e:
            logger.error(f"å¤„ç†åˆ‡ç‰‡æ ‡æ³¨å¤±è´¥: {str(e)}")
            return None
    
    def process_all_sliced_annotations(self) -> List[Dict]:
        """å¤„ç†æ‰€æœ‰åˆ‡ç‰‡æ ‡æ³¨ç”Ÿæˆæ•°æ®é›†"""
        # åŠ è½½æ‰€æœ‰æ ‡æ³¨
        all_annotations = self.load_all_annotations()
        if not all_annotations:
            return []
        
        # å»é‡
        unique_annotations = self.remove_duplicate_annotations(all_annotations)
        logger.info(f"å»é‡åå‰©ä½™ {len(unique_annotations)} ä¸ªå”¯ä¸€æ ‡æ³¨")
        
        # å¤„ç†æ¯ä¸ªåˆ‡ç‰‡æ ‡æ³¨
        llama_factory_data = []
        
        for ann in tqdm(unique_annotations, desc="å¤„ç†åˆ‡ç‰‡æ ‡æ³¨"):
            sample = self.process_single_sliced_annotation(ann)
            if sample:
                llama_factory_data.append(sample)
        
        logger.info(f"ç”Ÿæˆäº† {len(llama_factory_data)} ä¸ªLlama Factoryæ ¼å¼æ ·æœ¬")
        return llama_factory_data
    
    # -------------------------------------------------------------------------
    # <<< æ–°å¢æ–¹æ³•ï¼šæ‰“å°ç±»åˆ«ç»Ÿè®¡ >>>
    # -------------------------------------------------------------------------
    def print_data_stats(self, data: List[Dict], title: str = "æ•°æ®é›†ç»Ÿè®¡"):
        """æ‰“å°æ•°æ®é›†ä¸­å„ç±»åˆ«åˆ†å¸ƒæƒ…å†µ"""
        if not data:
            print(f"\nğŸ“Š {title}: æ— æ•°æ®")
            return
            
        counter = Counter([item.get('label_en', 'unknown') for item in data])
        total = len(data)
        sorted_counts = sorted(counter.items(), key=lambda x: x[1], reverse=True)
        
        print(f"\nğŸ“Š {title} (æ€»è®¡: {total}):")
        print("-" * 60)
        print(f"{'Category Label':<50} | {'Count':<6} | {'Ratio'}")
        print("-" * 60)
        for label, count in sorted_counts:
            ratio = (count / total) * 100
            print(f"{label[:48]:<50} | {count:<6} | {ratio:.1f}%")
        print("-" * 60)
        return sorted_counts

    # -------------------------------------------------------------------------
    # <<< æ–°å¢æ–¹æ³•ï¼šä¸Šé‡‡æ ·é€»è¾‘ >>>
    # -------------------------------------------------------------------------
    def upsample_data(self, data: List[Dict]) -> List[Dict]:
        """
        å¯¹æ•°æ®è¿›è¡Œä¸Šé‡‡æ ·ï¼šæ‰¾å‡ºæ•°é‡æœ€å¤šçš„ç±»åˆ«ï¼Œå°†å…¶ä»–ç±»åˆ«è¡¥å……åˆ°ç›¸åŒæ•°é‡ã€‚
        """
        if not data:
            return []
            
        # 1. æŒ‰ç±»åˆ«åˆ†ç»„
        category_map = defaultdict(list)
        for item in data:
            label = item.get('label_en', 'unknown')
            category_map[label].append(item)
            
        # 2. ç¡®å®šç›®æ ‡æ•°é‡ (æœ€å¤§ç±»çš„æ•°é‡)
        counts = {k: len(v) for k, v in category_map.items()}
        if not counts:
            return data
            
        max_count = max(counts.values())
        print(f"\nğŸ”„ æ­£åœ¨æ‰§è¡Œä¸Šé‡‡æ ·... ç›®æ ‡æ•°é‡: æ¯ä¸ªç±»åˆ« {max_count} ä¸ªæ ·æœ¬")
        
        balanced_data = []
        
        for label, items in category_map.items():
            current_count = len(items)
            # å…ˆåŠ å…¥åŸæœ‰æ•°æ®
            balanced_data.extend(items)
            
            # è®¡ç®—éœ€è¦è¡¥å……çš„æ•°é‡
            needed = max_count - current_count
            if needed > 0:
                # éšæœºé‡‡æ ·å¹¶æ·±æ‹·è´ (Deepcopyå¾ˆé‡è¦ï¼Œé˜²æ­¢ä¿®æ”¹å‰¯æœ¬å½±å“åŸä»¶)
                extras = random.choices(items, k=needed)
                extras_copy = [copy.deepcopy(x) for x in extras]
                balanced_data.extend(extras_copy)
                
        # æ‰“ä¹±é¡ºåº
        random.shuffle(balanced_data)
        return balanced_data

    def save_llama_factory_format(self, train_data: List[Dict], test_data: List[Dict]):
        """ä¿å­˜ä¸ºLlama Factoryæ ¼å¼"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = os.path.join(self.output_dir, f"llama_factory_vqa_{timestamp}")
        os.makedirs(output_path, exist_ok=True)
        
        # 1. ä¿å­˜è®­ç»ƒé›†
        train_file = os.path.join(output_path, "train.json")
        with open(train_file, 'w', encoding='utf-8') as f:
            json.dump(train_data, f, ensure_ascii=False, indent=2)
        logger.info(f"ä¿å­˜è®­ç»ƒé›†: {train_file} ({len(train_data)} ä¸ªæ ·æœ¬)")
        
        # 2. ä¿å­˜æµ‹è¯•é›†
        test_file = os.path.join(output_path, "test.json")
        with open(test_file, 'w', encoding='utf-8') as f:
            json.dump(test_data, f, ensure_ascii=False, indent=2)
        logger.info(f"ä¿å­˜æµ‹è¯•é›†: {test_file} ({len(test_data)} ä¸ªæ ·æœ¬)")
        
        # 3. ä¿å­˜å®Œæ•´æ•°æ®é›†
        all_data = train_data + test_data
        all_file = os.path.join(output_path, "data.json")
        with open(all_file, 'w', encoding='utf-8') as f:
            json.dump(all_data, f, ensure_ascii=False, indent=2)
        logger.info(f"ä¿å­˜å®Œæ•´æ•°æ®é›†: {all_file} ({len(all_data)} ä¸ªæ ·æœ¬)")
        
        # 4. åˆ›å»ºåŒ…å«systemå­—æ®µçš„dataset_info.json
        dataset_info = {
            "sliced_video_vqa_dataset": {
                "file_name": "data.json",
                "columns": {
                    "prompt": "instruction",
                    "query": "input", 
                    "response": "output",
                    "videos": "videos",
                    "system": "system"  # æ·»åŠ systemå­—æ®µæ˜ å°„
                }
            }
        }
        
        dataset_info_file = os.path.join(output_path, "dataset_info.json")
        with open(dataset_info_file, 'w', encoding='utf-8') as f:
            json.dump(dataset_info, f, ensure_ascii=False, indent=2)
        logger.info(f"ä¿å­˜dataset_info.json: {dataset_info_file}")
        
        return output_path
    
    def save_qwen3_sft_format(self, train_data: List[Dict], test_data: List[Dict]):
        """ä¿å­˜ä¸ºQWen3 SFTæ ¼å¼"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = os.path.join(self.output_dir, f"qwen3_sft_vqa_{timestamp}")
        os.makedirs(output_path, exist_ok=True)
        
        # 1. ä¿å­˜è®­ç»ƒé›†
        train_file = os.path.join(output_path, "qwen3_sft_train.json")
        with open(train_file, 'w', encoding='utf-8') as f:
            json.dump(train_data, f, ensure_ascii=False, indent=2)
        logger.info(f"ä¿å­˜è®­ç»ƒé›†: {train_file} ({len(train_data)} ä¸ªæ ·æœ¬)")
        
        # 2. ä¿å­˜æµ‹è¯•é›†
        test_file = os.path.join(output_path, "qwen3_sft_test.json")
        with open(test_file, 'w', encoding='utf-8') as f:
            json.dump(test_data, f, ensure_ascii=False, indent=2)
        logger.info(f"ä¿å­˜æµ‹è¯•é›†: {test_file} ({len(test_data)} ä¸ªæ ·æœ¬)")
        
        # 3. ä¿å­˜å®Œæ•´æ•°æ®é›†
        all_data = train_data + test_data
        all_file = os.path.join(output_path, "qwen3_sft_all.json")
        with open(all_file, 'w', encoding='utf-8') as f:
            json.dump(all_data, f, ensure_ascii=False, indent=2)
        logger.info(f"ä¿å­˜å®Œæ•´æ•°æ®é›†: {all_file} ({len(all_data)} ä¸ªæ ·æœ¬)")
        
        # 4. åˆ›å»ºQWen3 SFTæ ¼å¼çš„dataset_info.json
        dataset_info = {
            "qwen3_sft_vqa_dataset": {
                "file_name": "qwen3_sft_train.json",
                "columns": {
                    "prompt": "instruction",
                    "query": "input", 
                    "response": "output",
                    "videos": "videos",
                    "system": "system"  # æ·»åŠ systemå­—æ®µæ˜ å°„
                }
            }
        }
        
        dataset_info_file = os.path.join(output_path, "dataset_info.json")
        with open(dataset_info_file, 'w', encoding='utf-8') as f:
            json.dump(dataset_info, f, ensure_ascii=False, indent=2)
        logger.info(f"ä¿å­˜dataset_info.json: {dataset_info_file}")
        
        return output_path
    
    def check_video_tag_consistency(self, data: List[Dict]) -> Dict:
        """æ£€æŸ¥<video>æ ‡è®°å’Œè§†é¢‘æ•°é‡çš„ä¸€è‡´æ€§"""
        results = {
            "total_samples": len(data),
            "consistent_samples": 0,
            "inconsistent_samples": 0,
            "missing_video_tag": 0,
            "video_count_mismatch": 0,
            "details": []
        }
        
        for i, item in enumerate(data):
            instruction = item.get("instruction", "")
            videos = item.get("videos", [])
            
            # ç»Ÿè®¡<video>æ ‡è®°çš„æ•°é‡
            video_tags = instruction.count("<video>")
            
            # æ£€æŸ¥ä¸€è‡´æ€§
            is_consistent = (video_tags == len(videos))
            
            detail = {
                "sample_index": i,
                "video_tags_count": video_tags,
                "videos_count": len(videos),
                "is_consistent": is_consistent,
                "instruction_preview": instruction[:100] + "..." if len(instruction) > 100 else instruction
            }
            
            results["details"].append(detail)
            
            if is_consistent:
                results["consistent_samples"] += 1
            else:
                results["inconsistent_samples"] += 1
                if video_tags == 0:
                    results["missing_video_tag"] += 1
                if video_tags != len(videos):
                    results["video_count_mismatch"] += 1
        
        return results
    
    def check_system_prompt_inclusion(self, data: List[Dict]) -> Dict:
        """æ£€æŸ¥system promptæ˜¯å¦åŒ…å«"""
        results = {
            "total_samples": len(data),
            "with_system": 0,
            "without_system": 0,
            "system_prompt_lengths": []
        }
        
        for item in data:
            system_prompt = item.get("system", "")
            if system_prompt and system_prompt.strip():
                results["with_system"] += 1
                results["system_prompt_lengths"].append(len(system_prompt))
            else:
                results["without_system"] += 1
        
        if results["system_prompt_lengths"]:
            results["avg_system_length"] = sum(results["system_prompt_lengths"]) / len(results["system_prompt_lengths"])
        else:
            results["avg_system_length"] = 0
            
        return results

def main():
    """ä¸»å‡½æ•°"""
    # ä¿®æ”¹ä¸ºåˆ‡ç‰‡æ•°æ®é›†è·¯å¾„
    ANNOTATIONS_FILE = "/root/workspace/sliced_vqa_dataset_prepared/converted_sliced_annotations/simple_sliced_dataset.json"
    OUTPUT_DIR = "/root/workspace/llama_factory_sliced_vqa_dataset"
    
    print("=" * 60)
    print("Llama Factory åˆ‡ç‰‡è§†é¢‘VQAæ•°æ®é›†ç”Ÿæˆå·¥å…· (å«ä¸Šé‡‡æ ·å¹³è¡¡)")
    print("=" * 60)
    print("ğŸ“‹ å…³é”®ç‰¹æ€§:")
    print("  - ä¸“é—¨ä¸º20ç§’åˆ‡ç‰‡è§†é¢‘è®¾è®¡")
    print("  - instructionä¸­åŒ…å«<video>æ ‡è®°")
    print("  - videosåˆ—åŒ…å«åˆ‡ç‰‡è§†é¢‘è·¯å¾„")
    print("  - åŒ…å«system promptå­—æ®µ")
    print("  - æ”¯æŒQWen3 SFTæ ¼å¼")
    print("  - [æ–°å¢] è‡ªåŠ¨ä¸Šé‡‡æ ·å¹³è¡¡è®­ç»ƒé›†") # <--- æç¤º
    print("=" * 60)
    
    # æ£€æŸ¥æ ‡æ³¨æ–‡ä»¶
    if not os.path.exists(ANNOTATIONS_FILE):
        logger.error(f"æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {ANNOTATIONS_FILE}")
        print(f"\nâŒ é”™è¯¯: æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {ANNOTATIONS_FILE}")
        return
    
    if os.path.getsize(ANNOTATIONS_FILE) == 0:
        logger.error(f"æ ‡æ³¨æ–‡ä»¶ä¸ºç©º: {ANNOTATIONS_FILE}")
        print(f"\nâŒ é”™è¯¯: æ ‡æ³¨æ–‡ä»¶ä¸ºç©º: {ANNOTATIONS_FILE}")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # åˆå§‹åŒ–æ•°æ®é›†æ„å»ºå™¨
    builder = LlamaFactoryVQADatasetBuilder(
        annotations_file=ANNOTATIONS_FILE,
        output_dir=OUTPUT_DIR,
        train_ratio=0.8
    )
    
    # å¤„ç†æ‰€æœ‰åˆ‡ç‰‡æ ‡æ³¨
    llama_factory_data = builder.process_all_sliced_annotations()
    if not llama_factory_data:
        logger.error("æ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„æ ·æœ¬")
        print("\nâŒ é”™è¯¯: æ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„æ ·æœ¬")
        return
    
    # <--- æ–°å¢ï¼šæ‰“å°åŸå§‹æ•°æ®ç»Ÿè®¡ --->
    builder.print_data_stats(llama_factory_data, title="åŸå§‹æ•°æ®åˆ†å¸ƒ")
    
    # æ£€æŸ¥<video>æ ‡è®°ä¸€è‡´æ€§
    print("\nğŸ” æ£€æŸ¥<video>æ ‡è®°ä¸€è‡´æ€§...")
    consistency_check = builder.check_video_tag_consistency(llama_factory_data)
    
    print(f"âœ… ä¸€è‡´æ ·æœ¬: {consistency_check['consistent_samples']}/{consistency_check['total_samples']}")
    print(f"âŒ ä¸ä¸€è‡´æ ·æœ¬: {consistency_check['inconsistent_samples']}")
    
    if consistency_check['inconsistent_samples'] > 0:
        print(f"  - ç¼ºå°‘<video>æ ‡è®°: {consistency_check['missing_video_tag']}")
        print(f"  - è§†é¢‘æ•°é‡ä¸åŒ¹é…: {consistency_check['video_count_mismatch']}")
        
        # æ˜¾ç¤ºä¸ä¸€è‡´çš„æ ·æœ¬
        print("\nğŸ“‹ ä¸ä¸€è‡´æ ·æœ¬è¯¦æƒ…:")
        for detail in consistency_check['details'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            if not detail['is_consistent']:
                print(f"  æ ·æœ¬{detail['sample_index']}: {detail['instruction_preview']}")
                print(f"    <video>æ ‡è®°: {detail['video_tags_count']}, è§†é¢‘æ•°é‡: {detail['videos_count']}")
    
    # æ£€æŸ¥system prompt
    print("\nğŸ” æ£€æŸ¥system promptåŒ…å«æƒ…å†µ...")
    system_check = builder.check_system_prompt_inclusion(llama_factory_data)
    print(f"âœ… åŒ…å«system prompt: {system_check['with_system']}/{system_check['total_samples']}")
    print(f"âŒ ç¼ºå°‘system prompt: {system_check['without_system']}")
    print(f"ğŸ“Š å¹³å‡system prompté•¿åº¦: {system_check['avg_system_length']:.1f} å­—ç¬¦")
    
    # ç®€å•åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    random.shuffle(llama_factory_data)
    split_idx = int(len(llama_factory_data) * 0.8)
    
    # <--- ä¿®æ”¹ï¼šå…ˆåˆ’åˆ† --->
    train_data = llama_factory_data[:split_idx]
    test_data = llama_factory_data[split_idx:]
    
    print(f"\nğŸ“Š åˆå§‹åˆ’åˆ†:")
    print(f"  æ€»æ ·æœ¬æ•°: {len(llama_factory_data)}")
    print(f"  è®­ç»ƒé›†(Raw): {len(train_data)} ä¸ªæ ·æœ¬")
    print(f"  æµ‹è¯•é›†(Raw): {len(test_data)} ä¸ªæ ·æœ¬")

    # <--- æ–°å¢ï¼šä»…å¯¹è®­ç»ƒé›†è¿›è¡Œä¸Šé‡‡æ · --->
    print("\nğŸš€ æ­£åœ¨å¯¹è®­ç»ƒé›†è¿›è¡Œä¸Šé‡‡æ ·å¹³è¡¡...")
    train_data = builder.upsample_data(train_data)
    
    # <--- æ–°å¢ï¼šæ‰“å°ä¸Šé‡‡æ ·åçš„ç»Ÿè®¡ --->
    builder.print_data_stats(train_data, title="ä¸Šé‡‡æ ·åçš„è®­ç»ƒé›†åˆ†å¸ƒ")
    
    # ä¿å­˜ä¸ºLlama Factoryæ ¼å¼
    output_path_llama = builder.save_llama_factory_format(train_data, test_data)
    
    # ä¿å­˜ä¸ºQWen3 SFTæ ¼å¼
    output_path_qwen = builder.save_qwen3_sft_format(train_data, test_data)
    
    # æ˜¾ç¤ºæ ·æœ¬ç¤ºä¾‹
    print("\n" + "=" * 60)
    print("ğŸ“‹ æ•°æ®é›†æ ·æœ¬ç¤ºä¾‹")
    print("=" * 60)
    
    if train_data:
        print("\nè®­ç»ƒé›†æ ·æœ¬ (å‰2ä¸ª):")
        for i, sample in enumerate(train_data[:2], 1):
            print(f"\næ ·æœ¬ {i}:")
            print(f"  instruction: {sample.get('instruction', 'N/A')}")
            print(f"  input: '{sample.get('input', '')}'")
            print(f"  system: {sample.get('system', 'N/A')[:100]}...")
            print(f"  output: {sample.get('output', 'N/A')[:120]}...")
            video_path = sample.get('videos', [''])[0]
            print(f"  videos: ['{video_path[:60]}...']")
            print(f"  <video>æ ‡è®°æ•°é‡: {sample.get('instruction', '').count('<video>')}")
            print(f"  è§†é¢‘æ•°é‡: {len(sample.get('videos', []))}")
            print(f"  è§†é¢‘å­˜åœ¨: {os.path.exists(video_path) if video_path else False}")
            print(f"  åˆ‡ç‰‡key: {sample.get('slice_key', '')}")
    
    print("=" * 60)
    
    # æ˜¾ç¤ºLlama Factoryæ ¼å¼çš„dataset_info.jsonå†…å®¹
    dataset_info_file_llama = os.path.join(output_path_llama, "dataset_info.json")
    if os.path.exists(dataset_info_file_llama):
        with open(dataset_info_file_llama, 'r', encoding='utf-8') as f:
            dataset_info_llama = json.load(f)
        print(f"\nğŸ“ Llama Factoryæ ¼å¼ dataset_info.json é…ç½®:")
        for dataset_name, config in dataset_info_llama.items():
            print(f"  æ•°æ®é›†åç§°: {dataset_name}")
            print(f"  æ–‡ä»¶å: {config['file_name']}")
            print(f"  å­—æ®µæ˜ å°„:")
            for field, mapping in config['columns'].items():
                print(f"    {field}: {mapping}")
    
    # æ˜¾ç¤ºQWen3 SFTæ ¼å¼çš„dataset_info.jsonå†…å®¹
    dataset_info_file_qwen = os.path.join(output_path_qwen, "dataset_info.json")
    if os.path.exists(dataset_info_file_qwen):
        with open(dataset_info_file_qwen, 'r', encoding='utf-8') as f:
            dataset_info_qwen = json.load(f)
        print(f"\nğŸ“ QWen3 SFTæ ¼å¼ dataset_info.json é…ç½®:")
        for dataset_name, config in dataset_info_qwen.items():
            print(f"  æ•°æ®é›†åç§°: {dataset_name}")
            print(f"  æ–‡ä»¶å: {config['file_name']}")
            print(f"  å­—æ®µæ˜ å°„:")
            for field, mapping in config['columns'].items():
                print(f"    {field}: {mapping}")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æ•°æ®é›†ç”Ÿæˆå®Œæˆ")
    print("=" * 60)
    
    print(f"\nğŸ“ è¾“å‡ºç›®å½•:")
    print(f"  Llama Factoryæ ¼å¼: {output_path_llama}")
    print(f"  QWen3 SFTæ ¼å¼: {output_path_qwen}")
    
    print(f"\nğŸ“ Llama Factoryæ ¼å¼ç”Ÿæˆçš„æ–‡ä»¶:")
    for file in os.listdir(output_path_llama):
        file_path = os.path.join(output_path_llama, file)
        if os.path.isfile(file_path):
            size_kb = os.path.getsize(file_path) / 1024
            print(f"  ğŸ“„ {file} ({size_kb:.1f} KB)")
    
    print(f"\nğŸ“ QWen3 SFTæ ¼å¼ç”Ÿæˆçš„æ–‡ä»¶:")
    for file in os.listdir(output_path_qwen):
        file_path = os.path.join(output_path_qwen, file)
        if os.path.isfile(file_path):
            size_kb = os.path.getsize(file_path) / 1024
            print(f"  ğŸ“„ {file} ({size_kb:.1f} KB)")
    
    print(f"\nğŸš€ ä½¿ç”¨è¯´æ˜:")
    print("1. Llama Factoryæ ¼å¼ä½¿ç”¨:")
    print(f"   æ•°æ®é›†è·¯å¾„: {output_path_llama}")
    print(f"   æ•°æ®é›†åç§°: sliced_video_vqa_dataset")
    print("\n2. QWen3 SFTæ ¼å¼ä½¿ç”¨:")
    print(f"   æ•°æ®é›†è·¯å¾„: {output_path_qwen}")
    print(f"   æ•°æ®é›†åç§°: qwen3_sft_vqa_dataset")
    print("\n3. åœ¨Llama Factoryé…ç½®æ–‡ä»¶ä¸­æ·»åŠ :")
    print("""
dataset_info:
  sliced_video_vqa_dataset:
    file_name: train.json
    columns:
      prompt: instruction
      query: input
      response: output
      videos: videos
      system: system
""")
    print("\nğŸ’¡ æ³¨æ„: è®­ç»ƒæ—¶ä½¿ç”¨ train.jsonï¼Œè¯„ä¼°æ—¶ä½¿ç”¨ test.json")
    
    print("=" * 60)
    
    # éªŒè¯å…³é”®è¦æ±‚
    print("\nğŸ” Llama Factoryè¦æ±‚éªŒè¯:")
    print("âœ… æ¯ä¸ªæ ·æœ¬åŒ…å« videos åˆ—: æ˜¯")
    print("âœ… instruction ä¸­åŒ…å« <video> æ ‡è®°: æ˜¯")
    print("âœ… åŒ…å« system å­—æ®µ: æ˜¯")
    print("âœ… <video>æ ‡è®°æ•°é‡ä¸è§†é¢‘æ•°é‡ä¸€è‡´: æ˜¯ (1ä¸ªæ ‡è®°å¯¹åº”1ä¸ªè§†é¢‘)")
    print("âœ… videos åˆ—æ˜¯åˆ—è¡¨æ ¼å¼: æ˜¯")
    print("âœ… æ‰€æœ‰è§†é¢‘è·¯å¾„éƒ½å­˜åœ¨: å·²éªŒè¯")
    
    print("=" * 60)

if __name__ == "__main__":
    main()

