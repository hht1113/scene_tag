import os
import json
import random
import time
from typing import Dict, List, Tuple, Optional
import logging
from datetime import datetime
from tqdm import tqdm
import traceback
from collections import defaultdict
import re

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/root/workspace/video_vqa_dataset_generation.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# é—®é¢˜æ¨¡æ¿åˆ—è¡¨ - å…³äºè‡ªè½¦åŠ¨ä½œ
ENGLISH_QUESTION_TEMPLATES = [
    "What is the ego vehicle's action in the video?",
    "What is the ego vehicle doing in this video clip?",
    "What is the behavior of the ego vehicle?",
    "Please tell me the ego vehicle's action.",
    "What operation is the ego vehicle currently executing?",
    "What is the driving maneuver of the ego vehicle in this video?",
    "Identify the ego vehicle's action in the video.",
    "Describe the behavior of the ego vehicle.",
    "What is the operation of the ego vehicle?",
    "What is the vehicle's action shown in the video?",
    "What action is the ego vehicle executing?",
    "What is the ego vehicle's behavior in this video clip?",
    "Please explain the ego vehicle's action.",
    "What is the driving maneuver of the ego vehicle?",
    "What is the ego vehicle's operation in the video?",
    "What action is the ego vehicle completing in this video?",
    "What is the driving behavior of the ego vehicle?",
    "Please analyze the ego vehicle's action.",
    "What is the ego vehicle's action in the video?",
    "What did the ego vehicle do in the video?"
]

# å•åŠ¨ä½œç­”æ¡ˆæ¨¡æ¿åˆ—è¡¨
SINGLE_ANSWER_TEMPLATES = [
    "The ego vehicle's behavior from <start_time>start_time_value</start_time> to <end_time>end_time_value</end_time> seconds is <driving_maneuver>action</driving_maneuver>.",
    "The ego vehicle performs <driving_maneuver>action</driving_maneuver> between <start_time>start_time_value</start_time> and <end_time>end_time_value</end_time> seconds.",
    "From <start_time>start_time_value</start_time> to <end_time>end_time_value</end_time> seconds, the ego vehicle's action is <driving_maneuver>action</driving_maneuver>.",
    "The ego vehicle exhibits <driving_maneuver>action</driving_maneuver> behavior during <start_time>start_time_value</start_time> to <end_time>end_time_value</end_time> seconds.",
    "The primary action of the ego vehicle is <driving_maneuver>action</driving_maneuver> from <start_time>start_time_value</start_time> to <end_time>end_time_value</end_time> seconds.",
    "Between <start_time>start_time_value</start_time> and <end_time>end_time_value</end_time> seconds, the ego vehicle is <driving_maneuver>action</driving_maneuver>.",
    "During the interval <start_time>start_time_value</start_time> to <end_time>end_time_value</end_time> seconds, the ego vehicle's behavior is <driving_maneuver>action</driving_maneuver>.",
    "The ego vehicle executes <driving_maneuver>action</driving_maneuver> from <start_time>start_time_value</start_time> to <end_time>end_time_value</end_time> seconds.",
    "From <start_time>start_time_value</start_time> to <end_time>end_time_value</end_time> seconds, the ego vehicle engages in <driving_maneuver>action</driving_maneuver>.",
    "The ego vehicle's driving maneuver is <driving_maneuver>action</driving_maneuver> between <start_time>start_time_value</start_time> and <end_time>end_time_value</end_time> seconds."
]

class VideoVQADatasetBuilder:
    """è§†é¢‘VQAæ•°æ®é›†æ„å»ºå™¨ï¼ˆè§†é¢‘ç²’åº¦ï¼Œåˆå¹¶å¤šä¸ªåŠ¨ä½œï¼‰"""
    
    def __init__(self, annotations_file: str, output_dir: str, train_ratio: float = 0.8, 
                 merge_interval: int = 1):
        """
        åˆå§‹åŒ–æ•°æ®é›†æ„å»ºå™¨
        
        Args:
            annotations_file: æ ‡æ³¨æ–‡ä»¶è·¯å¾„ï¼ˆä½¿ç”¨è½¬æ¢åçš„æ ‡æ³¨æ–‡ä»¶ï¼‰
            output_dir: è¾“å‡ºç›®å½•
            train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
            merge_interval: åˆå¹¶é—´éš”ï¼ˆç§’ï¼‰ï¼Œç›¸é‚»åŠ¨ä½œé—´éš”å°äºç­‰äºæ­¤å€¼ä¼šè¢«åˆå¹¶
        """
        self.annotations_file = annotations_file
        self.output_dir = output_dir
        self.train_ratio = train_ratio
        self.merge_interval = merge_interval
        
    def load_all_annotations(self) -> List[Dict]:
        """åŠ è½½æ‰€æœ‰æ ‡æ³¨æ•°æ®ï¼Œå¹¶è¿›è¡Œå»é‡"""
        all_annotations = []
        
        try:
            with open(self.annotations_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            logger.info(f"ä» {self.annotations_file} åŠ è½½æ•°æ®ï¼Œæ•°æ®ç±»å‹: {type(data)}")
            
            # æ ¹æ®æ–‡ä»¶æ ¼å¼å¤„ç†
            if isinstance(data, list):
                all_annotations = data
                logger.info(f"ç›´æ¥åŠ è½½åˆ—è¡¨ï¼Œå…± {len(all_annotations)} ä¸ªæ ‡æ³¨")
            elif isinstance(data, dict) and "data" in data:
                all_annotations = data["data"]
                logger.info(f"ä»dataå­—æ®µåŠ è½½ï¼Œå…± {len(all_annotations)} ä¸ªæ ‡æ³¨")
            else:
                logger.error(f"æ ‡æ³¨æ–‡ä»¶æ ¼å¼ä¸æ”¯æŒ: {self.annotations_file}")
                return []
            
            logger.info(f"åˆå§‹åŠ è½½äº† {len(all_annotations)} ä¸ªæ ‡æ³¨")
            
            # å»é‡ï¼šåŸºäºidå»é‡
            seen_ids = set()
            unique_annotations = []
            duplicate_count = 0
            
            for ann in all_annotations:
                ann_id = ann.get('id', '')
                if not ann_id:
                    logger.warning(f"å‘ç°æ²¡æœ‰idçš„æ ‡æ³¨: {ann}")
                    unique_annotations.append(ann)  # æ²¡æœ‰idçš„ä¿ç•™
                elif ann_id in seen_ids:
                    duplicate_count += 1
                    logger.debug(f"å‘ç°é‡å¤æ ‡æ³¨ï¼Œid: {ann_id}")
                else:
                    seen_ids.add(ann_id)
                    unique_annotations.append(ann)
            
            if duplicate_count > 0:
                logger.warning(f"å‘ç° {duplicate_count} ä¸ªé‡å¤æ ‡æ³¨ï¼Œå·²å»é‡")
            
            all_annotations = unique_annotations
            logger.info(f"å»é‡åä¿ç•™ {len(all_annotations)} ä¸ªå”¯ä¸€æ ‡æ³¨")
            
            # åªä¿ç•™è§†é¢‘å­˜åœ¨çš„æ ‡æ³¨
            filtered_annotations = []
            for ann in all_annotations:
                video_exists = ann.get("video_exists", False)
                video_path = ann.get("video_path", "")
                
                if video_exists and video_path and os.path.exists(video_path):
                    filtered_annotations.append(ann)
                else:
                    logger.debug(f"è·³è¿‡è§†é¢‘ä¸å­˜åœ¨çš„æ ‡æ³¨: {ann.get('id', 'unknown')}")
            
            logger.info(f"è¿‡æ»¤åä¿ç•™ {len(filtered_annotations)} ä¸ªè§†é¢‘å­˜åœ¨çš„æ ‡æ³¨")
            
            return filtered_annotations
            
        except Exception as e:
            logger.error(f"åŠ è½½æ ‡æ³¨æ–‡ä»¶å¤±è´¥ {self.annotations_file}: {str(e)}")
            logger.error(traceback.format_exc())
            return []
    
    def group_by_video(self, annotations: List[Dict]) -> Dict[str, List[Dict]]:
        """æŒ‰è§†é¢‘è·¯å¾„åˆ†ç»„æ ‡æ³¨ï¼Œå¹¶å¯¹æ¯ä¸ªè§†é¢‘å†…çš„æ ‡æ³¨å»é‡"""
        video_groups = defaultdict(list)
        
        for ann in annotations:
            video_path = ann.get('video_path', '')
            if video_path:
                video_groups[video_path].append(ann)
        
        logger.info(f"æŒ‰è§†é¢‘åˆ†ç»„å®Œæˆ: {len(video_groups)} ä¸ªè§†é¢‘")
        
        # å¯¹æ¯ä¸ªè§†é¢‘å†…çš„æ ‡æ³¨è¿›è¡Œå»é‡
        clean_video_groups = {}
        for video_path, anns in video_groups.items():
            # åŸºäºidå»é‡
            seen_ids = set()
            unique_anns = []
            
            for ann in anns:
                ann_id = ann.get('id', '')
                if ann_id in seen_ids:
                    logger.warning(f"è§†é¢‘ {os.path.basename(video_path)} ä¸­æœ‰é‡å¤æ ‡æ³¨: {ann_id}")
                else:
                    seen_ids.add(ann_id)
                    unique_anns.append(ann)
            
            if len(anns) != len(unique_anns):
                logger.info(f"è§†é¢‘ {os.path.basename(video_path)}: {len(anns)} -> {len(unique_anns)} ä¸ªæ ‡æ³¨")
            
            clean_video_groups[video_path] = unique_anns
        
        # ç»Ÿè®¡æ¯ä¸ªè§†é¢‘çš„æ ‡æ³¨æ•°é‡
        for video_path, anns in list(clean_video_groups.items())[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
            logger.info(f"è§†é¢‘: {os.path.basename(video_path)}, æ ‡æ³¨æ•°: {len(anns)}")
            if len(anns) > 1:
                # æ£€æŸ¥æ˜¯å¦æœ‰å®Œå…¨ç›¸åŒçš„æ ‡æ³¨
                for i in range(len(anns)):
                    for j in range(i+1, len(anns)):
                        if (anns[i].get('label_en') == anns[j].get('label_en') and
                            anns[i].get('time_range') == anns[j].get('time_range')):
                            logger.warning(f"è§†é¢‘ {os.path.basename(video_path)} ä¸­æœ‰å®Œå…¨ç›¸åŒæ ‡æ³¨: {anns[i].get('id')}")
        
        return clean_video_groups
    
    def remove_duplicate_annotations(self, annotations: List[Dict]) -> List[Dict]:
        """ç§»é™¤é‡å¤çš„æ ‡æ³¨ï¼ˆåŸºäºæ ‡ç­¾å’Œæ—¶é—´èŒƒå›´ï¼‰"""
        if not annotations:
            return []
        
        seen = set()
        unique_annotations = []
        
        for ann in annotations:
            label_en = ann.get('label_en', '')
            time_range = tuple(ann.get('time_range', []))
            ann_id = ann.get('id', '')
            
            # åˆ›å»ºå”¯ä¸€æ ‡è¯†
            key = (label_en, time_range, ann_id)
            
            if key in seen:
                logger.debug(f"ç§»é™¤é‡å¤æ ‡æ³¨: {ann_id} - {label_en} - {time_range}")
            else:
                seen.add(key)
                unique_annotations.append(ann)
        
        if len(annotations) != len(unique_annotations):
            logger.info(f"å»é‡: {len(annotations)} -> {len(unique_annotations)}")
        return unique_annotations
    
    def merge_overlapping_actions(self, annotations: List[Dict]) -> List[Dict]:
        """
        åˆå¹¶é‡å æˆ–ç›¸é‚»çš„ç›¸åŒåŠ¨ä½œ
        
        åˆå¹¶æ¡ä»¶ï¼š
        1. ç›¸åŒæ ‡ç­¾çš„åŠ¨ä½œ
        2. æ—¶é—´èŒƒå›´é‡å æˆ–ç›¸é‚»ï¼ˆé—´éš”å°äºç­‰äºmerge_intervalç§’ï¼‰
        3. åˆå¹¶åçš„æ—¶é—´èŒƒå›´å–æœ€æ—©å¼€å§‹æ—¶é—´å’Œæœ€æ™šç»“æŸæ—¶é—´
        """
        if not annotations:
            return []
        
        # æŒ‰æ ‡ç­¾åˆ†ç»„
        label_groups = defaultdict(list)
        for ann in annotations:
            label = ann.get('label_en', '')
            if label:
                label_groups[label].append(ann)
        
        merged_annotations = []
        
        for label, label_anns in label_groups.items():
            if len(label_anns) == 1:
                # åªæœ‰ä¸€ä¸ªåŠ¨ä½œï¼Œç›´æ¥æ·»åŠ 
                merged_annotations.append(label_anns[0])
                continue
            
            # æŒ‰å¼€å§‹æ—¶é—´æ’åº
            sorted_anns = sorted(label_anns, key=lambda x: x.get('time_range', [0])[0])
            
            # åˆå¹¶é‡å æˆ–ç›¸é‚»çš„æ—¶é—´åŒºé—´
            merged_ranges = []
            current_range = None
            current_anns = []
            
            for ann in sorted_anns:
                time_range = ann.get('time_range', [])
                if len(time_range) < 2:
                    continue
                
                start_time = time_range[0]
                end_time = time_range[1]
                
                if current_range is None:
                    # ç¬¬ä¸€ä¸ªåŒºé—´
                    current_range = [start_time, end_time]
                    current_anns = [ann]
                else:
                    # æ£€æŸ¥æ˜¯å¦é‡å æˆ–ç›¸é‚»
                    if start_time <= current_range[1] + self.merge_interval:
                        # é‡å æˆ–ç›¸é‚»ï¼Œåˆå¹¶
                        current_range[1] = max(current_range[1], end_time)
                        current_anns.append(ann)
                    else:
                        # ä¸é‡å ï¼Œä¿å­˜å½“å‰åŒºé—´ï¼Œå¼€å§‹æ–°çš„åŒºé—´
                        if current_range:
                            # åˆ›å»ºåˆå¹¶åçš„æ ‡æ³¨
                            merged_ann = self._create_merged_annotation(current_anns, current_range)
                            merged_annotations.append(merged_ann)
                        
                        current_range = [start_time, end_time]
                        current_anns = [ann]
            
            # å¤„ç†æœ€åä¸€ä¸ªåŒºé—´
            if current_range and current_anns:
                merged_ann = self._create_merged_annotation(current_anns, current_range)
                merged_annotations.append(merged_ann)
        
        if len(annotations) != len(merged_annotations):
            logger.info(f"åˆå¹¶åŠ¨ä½œ: {len(annotations)} -> {len(merged_annotations)}")
            for ann in merged_annotations:
                if 'merged_from' in ann:
                    logger.debug(f"åˆå¹¶åŠ¨ä½œ: {ann['label_en']} {ann['time_range']} æ¥è‡ª {len(ann['merged_from'])} ä¸ªæ ‡æ³¨")
        
        return merged_annotations
    
    def _create_merged_annotation(self, original_anns: List[Dict], merged_range: List[int]) -> Dict:
        """åˆ›å»ºåˆå¹¶åçš„æ ‡æ³¨"""
        if not original_anns:
            return None
        
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ ‡æ³¨ä½œä¸ºåŸºç¡€
        base_ann = original_anns[0].copy()
        
        # æ›´æ–°æ—¶é—´èŒƒå›´
        base_ann['time_range'] = merged_range
        base_ann['duration'] = merged_range[1] - merged_range[0]
        
        # è®°å½•åˆå¹¶ä¿¡æ¯
        base_ann['merged_from'] = [
            {
                'id': ann.get('id', ''),
                'time_range': ann.get('time_range', []),
                'duration': ann.get('duration', 0)
            }
            for ann in original_anns
        ]
        
        # æ›´æ–°ID
        base_ann['id'] = f"merged_{len(original_anns)}_{hash(tuple(merged_range)) % 10000:04d}"
        
        return base_ann
    
    def generate_single_action_description(self, action: Dict) -> str:
        """ç”Ÿæˆå•ä¸ªåŠ¨ä½œçš„æè¿°"""
        label_en = action.get('label_en', '')
        time_range = action.get('time_range', [])
        
        if not label_en or len(time_range) < 2:
            return ""
        
        # è·å–æ—¶é—´èŒƒå›´
        start_time = int(time_range[0])
        end_time = int(time_range[1])
        
        # éšæœºé€‰æ‹©ä¸€ä¸ªå•åŠ¨ä½œæ¨¡æ¿
        template = random.choice(SINGLE_ANSWER_TEMPLATES)
        
        # æ›¿æ¢æ¨¡æ¿ä¸­çš„æ ‡ç­¾
        description = template.replace(
            "<start_time>start_time_value</start_time>", 
            f"<start_time>{start_time}</start_time>"
        ).replace(
            "<end_time>end_time_value</end_time>", 
            f"<end_time>{end_time}</end_time>"
        ).replace(
            "<driving_maneuver>action</driving_maneuver>", 
            f"<driving_maneuver>{label_en}</driving_maneuver>"
        )
        
        return description
    
    def merge_actions_for_video(self, video_annotations: List[Dict]) -> Dict:
        """åˆå¹¶åŒä¸€è§†é¢‘çš„å¤šä¸ªåŠ¨ä½œä¸ºä¸€ä¸ªç»¼åˆæè¿°ï¼Œå…ˆè¿›è¡Œå»é‡å’Œåˆå¹¶"""
        if not video_annotations:
            return None
        
        # å…ˆå»é‡
        unique_annotations = self.remove_duplicate_annotations(video_annotations)
        if not unique_annotations:
            logger.warning(f"å»é‡åæ²¡æœ‰æ ‡æ³¨")
            return None
        
        # åˆå¹¶é‡å æˆ–ç›¸é‚»çš„ç›¸åŒåŠ¨ä½œ
        merged_annotations = self.merge_overlapping_actions(unique_annotations)
        if not merged_annotations:
            logger.warning(f"åˆå¹¶åæ²¡æœ‰æ ‡æ³¨")
            return None
        
        # æŒ‰å¼€å§‹æ—¶é—´æ’åº
        sorted_annotations = sorted(merged_annotations, 
                                   key=lambda x: x.get('time_range', [0])[0])
        
        video_path = sorted_annotations[0].get('video_path', '')
        video_exists = sorted_annotations[0].get('video_exists', False)
        
        if not video_path or not video_exists:
            return None
        
        # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(video_path):
            logger.warning(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            return None
        
        # è·å–è§†é¢‘æ—¶é•¿ï¼ˆä»æ ‡æ³¨ä¸­è·å–ï¼‰
        durations = [ann.get('duration', 0) for ann in sorted_annotations]
        if durations:
            video_duration = max(durations)  # ä½¿ç”¨æœ€å¤§çš„æŒç»­æ—¶é—´
        else:
            video_duration = 60  # é»˜è®¤60ç§’
        
        # ç”Ÿæˆé—®é¢˜
        question = random.choice(ENGLISH_QUESTION_TEMPLATES)
        
        # ç”Ÿæˆæ¯ä¸ªåŠ¨ä½œçš„æè¿°
        action_descriptions = []
        for ann in sorted_annotations:
            description = self.generate_single_action_description(ann)
            if description:
                action_descriptions.append(description)
        
        if not action_descriptions:
            logger.warning(f"æ— æ³•ä¸ºè§†é¢‘ç”ŸæˆåŠ¨ä½œæè¿°: {video_path}")
            return None
        
        # è¿æ¥æ‰€æœ‰åŠ¨ä½œæè¿°
        if len(action_descriptions) == 1:
            answer = action_descriptions[0]
        else:
            # éšæœºé€‰æ‹©è¿æ¥æ–¹å¼
            connector = random.choice(["; ", " and "])
            answer = connector.join(action_descriptions)
        
        # è·å–æ‰€æœ‰æ ‡ç­¾
        all_labels = []
        for ann in sorted_annotations:
            label_en = ann.get('label_en', '')
            if label_en:
                all_labels.append(label_en)
        
        # è·å–æ‰€æœ‰æ ‡æ³¨çš„è¯¦ç»†ä¿¡æ¯
        annotations_info = []
        for ann in sorted_annotations:
            time_range = ann.get('time_range', [])
            if len(time_range) >= 2:
                start_time = int(time_range[0])
                end_time = int(time_range[1])
            else:
                start_time = 0
                end_time = 0
            
            annotation_info = {
                "label_en": ann.get('label_en', ''),
                "label_zh": ann.get('label_zh', ''),
                "time_range_seconds": time_range,
                "time_range_frames": [start_time, end_time],  # å¸§æ•°ç­‰äºç§’æ•°
                "duration_seconds": ann.get('duration', 0),
                "original_annotation_id": ann.get('id', '')
            }
            
            # æ·»åŠ åˆå¹¶ä¿¡æ¯
            if 'merged_from' in ann:
                annotation_info['merged_from'] = ann['merged_from']
                annotation_info['merged_count'] = len(ann['merged_from'])
            
            annotations_info.append(annotation_info)
        
        # è®¡ç®—ä¸»è¦æ ‡ç­¾ï¼ˆå‡ºç°æ¬¡æ•°æœ€å¤šçš„æ ‡ç­¾ï¼‰
        if all_labels:
            from collections import Counter
            label_counter = Counter(all_labels)
            primary_label = label_counter.most_common(1)[0][0]
        else:
            primary_label = ""
        
        # è·å–è§†é¢‘æ–‡ä»¶å¤§å°
        try:
            file_size = os.path.getsize(video_path)
            file_size_mb = file_size / (1024 * 1024)
        except:
            file_size = 0
            file_size_mb = 0
        
        return {
            "id": f"video_{len(sorted_annotations)}_{hash(video_path) % 10000:04d}",
            "video_path": video_path,
            "video_filename": os.path.basename(video_path),
            "video_exists": True,
            "video_duration": video_duration,
            "video_size": file_size,
            "video_size_mb": file_size_mb,
            "question": question,
            "answer": answer,
            "primary_label": primary_label,
            "all_labels": list(set(all_labels)),
            "num_actions": len(sorted_annotations),
            "merged_actions_count": sum(1 for ann in sorted_annotations if 'merged_from' in ann),
            "total_original_actions": len(video_annotations),
            "annotations": annotations_info,
            "video_info": {
                "video_duration": video_duration,
                "total_frames": video_duration,  # æ¯ç§’1å¸§
                "has_multiple_actions": len(sorted_annotations) > 1
            }
        }
    
    def process_video_groups(self, video_groups: Dict[str, List[Dict]]) -> List[Dict]:
        """å¤„ç†æ‰€æœ‰è§†é¢‘ç»„ï¼Œç”Ÿæˆè§†é¢‘ç²’åº¦çš„æ•°æ®é›†"""
        video_samples = []
        skipped_videos = 0
        
        for video_path, annotations in tqdm(video_groups.items(), desc="å¤„ç†è§†é¢‘"):
            # æ£€æŸ¥æ ‡æ³¨æ•°é‡
            if len(annotations) > 10:
                logger.warning(f"è§†é¢‘ {os.path.basename(video_path)} æœ‰ {len(annotations)} ä¸ªæ ‡æ³¨ï¼Œå¯èƒ½å­˜åœ¨é‡å¤æˆ–éœ€è¦åˆå¹¶")
            
            # åˆå¹¶åŒä¸€è§†é¢‘çš„æ‰€æœ‰åŠ¨ä½œ
            video_sample = self.merge_actions_for_video(annotations)
            
            if video_sample:
                video_samples.append(video_sample)
            else:
                skipped_videos += 1
        
        logger.info(f"ç”Ÿæˆäº† {len(video_samples)} ä¸ªè§†é¢‘æ ·æœ¬ï¼Œè·³è¿‡äº† {skipped_videos} ä¸ªè§†é¢‘")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤çš„æ ·æœ¬
        video_paths = set()
        duplicate_samples = 0
        for sample in video_samples:
            video_path = sample.get('video_path', '')
            if video_path in video_paths:
                duplicate_samples += 1
                logger.warning(f"å‘ç°é‡å¤è§†é¢‘æ ·æœ¬: {video_path}")
            else:
                video_paths.add(video_path)
        
        if duplicate_samples > 0:
            logger.warning(f"å‘ç° {duplicate_samples} ä¸ªé‡å¤è§†é¢‘æ ·æœ¬")
        
        return video_samples
    
    def split_by_category(self, video_samples: List[Dict]) -> Tuple[List[Dict], List[Dict]]:
        """æŒ‰ç±»åˆ«åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼ˆæ¯ä¸ªç±»åˆ«80%è®­ç»ƒï¼Œ20%æµ‹è¯•ï¼‰"""
        if not video_samples:
            return [], []
        
        # æŒ‰ä¸»è¦æ ‡ç­¾åˆ†ç»„
        category_groups = defaultdict(list)
        for sample in video_samples:
            primary_label = sample.get('primary_label', 'unknown')
            category_groups[primary_label].append(sample)
        
        train_data = []
        test_data = []
        
        # å¯¹æ¯ä¸ªç±»åˆ«è¿›è¡Œåˆ’åˆ†
        for category, items in category_groups.items():
            if len(items) < 2:  # å¦‚æœç±»åˆ«æ ·æœ¬å¤ªå°‘ï¼Œå…¨éƒ¨æ”¾å…¥è®­ç»ƒé›†
                train_data.extend(items)
                logger.warning(f"ç±»åˆ« '{category}' åªæœ‰ {len(items)} ä¸ªæ ·æœ¬ï¼Œå…¨éƒ¨æ”¾å…¥è®­ç»ƒé›†")
                continue
            
            # æ‰“ä¹±é¡ºåº
            random.shuffle(items)
            
            # è®¡ç®—åˆ†å‰²ç‚¹
            split_idx = int(len(items) * self.train_ratio)
            
            if split_idx == 0:  # ç¡®ä¿è®­ç»ƒé›†è‡³å°‘æœ‰ä¸€ä¸ªæ ·æœ¬
                split_idx = 1
            
            train_data.extend(items[:split_idx])
            test_data.extend(items[split_idx:])
            
            logger.info(f"ç±»åˆ« '{category}': {len(items)}ä¸ªæ ·æœ¬ -> è®­ç»ƒ{len(items[:split_idx])}, æµ‹è¯•{len(items[split_idx:])}")
        
        # å†æ¬¡æ‰“ä¹±
        random.shuffle(train_data)
        random.shuffle(test_data)
        
        logger.info(f"æ€»ä½“åˆ’åˆ†: è®­ç»ƒé›†{len(train_data)}ä¸ªè§†é¢‘æ ·æœ¬, æµ‹è¯•é›†{len(test_data)}ä¸ªè§†é¢‘æ ·æœ¬")
        return train_data, test_data
    
    def save_dataset(self, train_data: List[Dict], test_data: List[Dict]):
        """ä¿å­˜æ•°æ®é›†"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = os.path.join(self.output_dir, f"video_vqa_dataset_{timestamp}")
        os.makedirs(output_path, exist_ok=True)
        
        # 1. ä¿å­˜è®­ç»ƒé›†
        train_file = os.path.join(output_path, "train.json")
        train_dataset = {
            "version": "1.0.0",
            "description": "Video VQA Training Dataset (Video-level, multiple actions merged)",
            "created": datetime.now().isoformat(),
            "config": {
                "merge_interval": self.merge_interval,
                "train_ratio": self.train_ratio
            },
            "statistics": {
                "total_samples": len(train_data),
                "categories_count": len(set([item.get('primary_label', '') for item in train_data])),
                "total_actions": sum([item.get('num_actions', 0) for item in train_data]),
                "merged_actions": sum([item.get('merged_actions_count', 0) for item in train_data]),
                "avg_actions_per_video": sum([item.get('num_actions', 0) for item in train_data]) / len(train_data) if train_data else 0
            },
            "data": train_data
        }
        
        with open(train_file, 'w', encoding='utf-8') as f:
            json.dump(train_dataset, f, ensure_ascii=False, indent=2)
        logger.info(f"ä¿å­˜è®­ç»ƒé›†: {train_file} ({len(train_data)} ä¸ªæ ·æœ¬)")
        
        # 2. ä¿å­˜æµ‹è¯•é›†
        test_file = os.path.join(output_path, "test.json")
        test_dataset = {
            "version": "1.0.0",
            "description": "Video VQA Test Dataset (Video-level, multiple actions merged)",
            "created": datetime.now().isoformat(),
            "config": {
                "merge_interval": self.merge_interval,
                "train_ratio": self.train_ratio
            },
            "statistics": {
                "total_samples": len(test_data),
                "categories_count": len(set([item.get('primary_label', '') for item in test_data])),
                "total_actions": sum([item.get('num_actions', 0) for item in test_data]),
                "merged_actions": sum([item.get('merged_actions_count', 0) for item in test_data]),
                "avg_actions_per_video": sum([item.get('num_actions', 0) for item in test_data]) / len(test_data) if test_data else 0
            },
            "data": test_data
        }
        
        with open(test_file, 'w', encoding='utf-8') as f:
            json.dump(test_dataset, f, ensure_ascii=False, indent=2)
        logger.info(f"ä¿å­˜æµ‹è¯•é›†: {test_file} ({len(test_data)} ä¸ªæ ·æœ¬)")
        
        # 3. ä¿å­˜å®Œæ•´æ•°æ®é›†
        all_data = train_data + test_data
        all_file = os.path.join(output_path, "all_data.json")
        all_dataset = {
            "version": "1.0.0",
            "description": "Video VQA Complete Dataset (Video-level, multiple actions merged)",
            "created": datetime.now().isoformat(),
            "config": {
                "merge_interval": self.merge_interval,
                "train_ratio": self.train_ratio
            },
            "statistics": {
                "total_samples": len(all_data),
                "train_samples": len(train_data),
                "test_samples": len(test_data),
                "train_ratio": self.train_ratio,
                "categories_count": len(set([item.get('primary_label', '') for item in all_data])),
                "total_actions": sum([item.get('num_actions', 0) for item in all_data]),
                "merged_actions": sum([item.get('merged_actions_count', 0) for item in all_data]),
                "avg_actions_per_video": sum([item.get('num_actions', 0) for item in all_data]) / len(all_data) if all_data else 0
            },
            "data": all_data
        }
        
        with open(all_file, 'w', encoding='utf-8') as f:
            json.dump(all_dataset, f, ensure_ascii=False, indent=2)
        logger.info(f"ä¿å­˜å®Œæ•´æ•°æ®é›†: {all_file} ({len(all_data)} ä¸ªæ ·æœ¬)")
        
        # 4. ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        stats = self.calculate_statistics(train_data, test_data)
        stats_file = os.path.join(output_path, "statistics.json")
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        
        # 5. ä¿å­˜ç±»åˆ«ä¿¡æ¯
        categories = self.extract_category_info(all_data)
        categories_file = os.path.join(output_path, "categories.json")
        with open(categories_file, 'w', encoding='utf-8') as f:
            json.dump(categories, f, ensure_ascii=False, indent=2)
        
        logger.info(f"æ•°æ®é›†å·²ä¿å­˜åˆ°: {output_path}")
        return output_path, stats
    
    def calculate_statistics(self, train_data: List[Dict], test_data: List[Dict]) -> Dict:
        """è®¡ç®—æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        # è®­ç»ƒé›†ç»Ÿè®¡
        train_videos = set()
        train_categories = defaultdict(int)
        train_actions_counts = []
        train_merged_counts = []
        train_original_actions_counts = []
        
        for item in train_data:
            video_path = item.get('video_path', '')
            if video_path:
                train_videos.add(video_path)
            
            primary_label = item.get('primary_label', 'unknown')
            train_categories[primary_label] += 1
            
            num_actions = item.get('num_actions', 0)
            train_actions_counts.append(num_actions)
            
            merged_actions = item.get('merged_actions_count', 0)
            train_merged_counts.append(merged_actions)
            
            total_original = item.get('total_original_actions', 0)
            train_original_actions_counts.append(total_original)
        
        # æµ‹è¯•é›†ç»Ÿè®¡
        test_videos = set()
        test_categories = defaultdict(int)
        test_actions_counts = []
        test_merged_counts = []
        test_original_actions_counts = []
        
        for item in test_data:
            video_path = item.get('video_path', '')
            if video_path:
                test_videos.add(video_path)
            
            primary_label = item.get('primary_label', 'unknown')
            test_categories[primary_label] += 1
            
            num_actions = item.get('num_actions', 0)
            test_actions_counts.append(num_actions)
            
            merged_actions = item.get('merged_actions_count', 0)
            test_merged_counts.append(merged_actions)
            
            total_original = item.get('total_original_actions', 0)
            test_original_actions_counts.append(total_original)
        
        # è®¡ç®—å¹³å‡åŠ¨ä½œæ•°é‡
        avg_train_actions = sum(train_actions_counts) / len(train_actions_counts) if train_actions_counts else 0
        avg_test_actions = sum(test_actions_counts) / len(test_actions_counts) if test_actions_counts else 0
        
        # è®¡ç®—åˆå¹¶ç»Ÿè®¡
        total_merged_train = sum(train_merged_counts)
        total_merged_test = sum(test_merged_counts)
        total_original_train = sum(train_original_actions_counts)
        total_original_test = sum(test_original_actions_counts)
        
        # è®¡ç®—è§†é¢‘æ—¶é•¿ç»Ÿè®¡
        train_durations = [item.get('video_duration', 0) for item in train_data]
        test_durations = [item.get('video_duration', 0) for item in test_data]
        
        stats = {
            "dataset_info": {
                "total_videos": len(train_data) + len(test_data),
                "train_videos": len(train_data),
                "test_videos": len(test_data),
                "train_ratio": self.train_ratio,
                "merge_interval": self.merge_interval,
                "generation_time": datetime.now().isoformat()
            },
            "video_info": {
                "unique_videos_train": len(train_videos),
                "unique_videos_test": len(test_videos),
                "unique_videos_total": len(train_videos.union(test_videos)),
                "avg_video_duration_train": sum(train_durations) / len(train_durations) if train_durations else 0,
                "avg_video_duration_test": sum(test_durations) / len(test_durations) if test_durations else 0,
                "max_video_duration_train": max(train_durations) if train_durations else 0,
                "max_video_duration_test": max(test_durations) if test_durations else 0
            },
            "category_info": {
                "total_categories": len(set(list(train_categories.keys()) + list(test_categories.keys()))),
                "train_categories": dict(sorted(train_categories.items(), key=lambda x: x[1], reverse=True)),
                "test_categories": dict(sorted(test_categories.items(), key=lambda x: x[1], reverse=True))
            },
            "action_info": {
                "avg_actions_per_video_train": avg_train_actions,
                "avg_actions_per_video_test": avg_test_actions,
                "max_actions_train": max(train_actions_counts) if train_actions_counts else 0,
                "max_actions_test": max(test_actions_counts) if test_actions_counts else 0,
                "min_actions_train": min(train_actions_counts) if train_actions_counts else 0,
                "min_actions_test": min(test_actions_counts) if test_actions_counts else 0,
                "total_actions_train": sum(train_actions_counts),
                "total_actions_test": sum(test_actions_counts)
            },
            "merge_info": {
                "total_merged_actions_train": total_merged_train,
                "total_merged_actions_test": total_merged_test,
                "total_original_actions_train": total_original_train,
                "total_original_actions_test": total_original_test,
                "compression_rate_train": (total_original_train - sum(train_actions_counts)) / total_original_train if total_original_train > 0 else 0,
                "compression_rate_test": (total_original_test - sum(test_actions_counts)) / total_original_test if total_original_test > 0 else 0
            },
            "generation_info": {
                "question_templates": len(ENGLISH_QUESTION_TEMPLATES),
                "answer_templates": len(SINGLE_ANSWER_TEMPLATES)
            }
        }
        
        return stats
    
    def extract_category_info(self, all_data: List[Dict]) -> Dict:
        """æå–ç±»åˆ«ä¿¡æ¯"""
        categories = {}
        
        for item in all_data:
            primary_label = item.get('primary_label', '')
            all_labels = item.get('all_labels', [])
            
            if not primary_label:
                continue
                
            if primary_label not in categories:
                categories[primary_label] = {
                    "label": primary_label,
                    "count": 0,
                    "all_labels_in_category": set(),
                    "example_questions": set(),
                    "example_answers": set(),
                    "videos": []
                }
            
            categories[primary_label]["count"] += 1
            
            # æ·»åŠ æ‰€æœ‰æ ‡ç­¾
            for label in all_labels:
                categories[primary_label]["all_labels_in_category"].add(label)
            
            # æ·»åŠ ç¤ºä¾‹é—®é¢˜å’Œç­”æ¡ˆ
            categories[primary_label]["example_questions"].add(item.get('question', ''))
            categories[primary_label]["example_answers"].add(item.get('answer', ''))
            
            # æ·»åŠ è§†é¢‘ä¿¡æ¯
            video_info = {
                "id": item.get('id', ''),
                "video_filename": item.get('video_filename', ''),
                "num_actions": item.get('num_actions', 0),
                "merged_actions": item.get('merged_actions_count', 0)
            }
            categories[primary_label]["videos"].append(video_info)
        
        # è½¬æ¢setä¸ºlist
        for cat in categories.values():
            cat["all_labels_in_category"] = list(cat["all_labels_in_category"])
            cat["example_questions"] = list(cat["example_questions"])[:3]  # åªä¿ç•™3ä¸ªç¤ºä¾‹é—®é¢˜
            cat["example_answers"] = list(cat["example_answers"])[:3]  # åªä¿ç•™3ä¸ªç¤ºä¾‹ç­”æ¡ˆ
        
        return categories
    
    def generate_sample_output(self, train_data: List[Dict], test_data: List[Dict], output_path: str):
        """ç”Ÿæˆæ ·æœ¬è¾“å‡ºæ–‡ä»¶ï¼Œç”¨äºæŸ¥çœ‹æ ¼å¼"""
        samples_file = os.path.join(output_path, "samples.json")
        
        samples = {
            "train_samples": train_data[:2] if len(train_data) >= 2 else train_data,
            "test_samples": test_data[:2] if len(test_data) >= 2 else test_data
        }
        
        with open(samples_file, 'w', encoding='utf-8') as f:
            json.dump(samples, f, ensure_ascii=False, indent=2)
        
        logger.info(f"æ ·æœ¬æ–‡ä»¶å·²ä¿å­˜: {samples_file}")
        
        # åœ¨æ§åˆ¶å°æ˜¾ç¤ºæ ·æœ¬
        print("\n" + "=" * 60)
        print("ğŸ“‹ æ•°æ®é›†æ ·æœ¬ç¤ºä¾‹")
        print("=" * 60)
        
        if train_data:
            print("\nè®­ç»ƒé›†æ ·æœ¬ (å‰2ä¸ª):")
            for i, sample in enumerate(train_data[:2], 1):
                print(f"\næ ·æœ¬ {i}:")
                print(f"  ID: {sample.get('id', 'N/A')}")
                print(f"  è§†é¢‘: {sample.get('video_filename', 'N/A')}")
                print(f"  è§†é¢‘è·¯å¾„: {sample.get('video_path', 'N/A')[:80]}...")
                print(f"  è§†é¢‘æ—¶é•¿: {sample.get('video_duration', 'N/A')}ç§’")
                print(f"  è§†é¢‘å¤§å°: {sample.get('video_size_mb', 0):.1f} MB")
                print(f"  é—®é¢˜: {sample.get('question', 'N/A')}")
                print(f"  ç­”æ¡ˆ: {sample.get('answer', 'N/A')}")
                print(f"  ä¸»è¦æ ‡ç­¾: {sample.get('primary_label', 'N/A')}")
                print(f"  æ‰€æœ‰æ ‡ç­¾: {sample.get('all_labels', [])}")
                print(f"  åŠ¨ä½œæ•°é‡: {sample.get('num_actions', 0)}")
                print(f"  åˆå¹¶åŠ¨ä½œæ•°: {sample.get('merged_actions_count', 0)}")
                print(f"  åŸå§‹æ ‡æ³¨æ•°: {sample.get('total_original_actions', 0)}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤åŠ¨ä½œ
                annotations = sample.get('annotations', [])
                if annotations:
                    # æ£€æŸ¥åˆå¹¶ä¿¡æ¯
                    for j, ann in enumerate(annotations[:3], 1):  # æ˜¾ç¤ºå‰3ä¸ªæ ‡æ³¨
                        label = ann.get('label_en', 'unknown')
                        time_range = ann.get('time_range_frames', [0, 0])
                        merged_count = ann.get('merged_count', 0)
                        if merged_count > 0:
                            print(f"    {j}. {label}: {time_range[0]}-{time_range[1]}ç§’ (åˆå¹¶äº†{merged_count}ä¸ªæ ‡æ³¨)")
                        else:
                            print(f"    {j}. {label}: {time_range[0]}-{time_range[1]}ç§’")
                    if len(annotations) > 3:
                        print(f"    ... è¿˜æœ‰ {len(annotations) - 3} ä¸ªæ ‡æ³¨")
        
        if test_data:
            print(f"\næµ‹è¯•é›†æ ·æœ¬ (å‰2ä¸ª):")
            for i, sample in enumerate(test_data[:2], 1):
                print(f"\næ ·æœ¬ {i}:")
                print(f"  ID: {sample.get('id', 'N/A')}")
                print(f"  è§†é¢‘: {sample.get('video_filename', 'N/A')}")
                print(f"  è§†é¢‘è·¯å¾„: {sample.get('video_path', 'N/A')[:80]}...")
                print(f"  è§†é¢‘æ—¶é•¿: {sample.get('video_duration', 'N/A')}ç§’")
                print(f"  è§†é¢‘å¤§å°: {sample.get('video_size_mb', 0):.1f} MB")
                print(f"  é—®é¢˜: {sample.get('question', 'N/A')}")
                print(f"  ç­”æ¡ˆ: {sample.get('answer', 'N/A')}")
                print(f"  ä¸»è¦æ ‡ç­¾: {sample.get('primary_label', 'N/A')}")
                print(f"  æ‰€æœ‰æ ‡ç­¾: {sample.get('all_labels', [])}")
                print(f"  åŠ¨ä½œæ•°é‡: {sample.get('num_actions', 0)}")
                print(f"  åˆå¹¶åŠ¨ä½œæ•°: {sample.get('merged_actions_count', 0)}")
                print(f"  åŸå§‹æ ‡æ³¨æ•°: {sample.get('total_original_actions', 0)}")
        
        print("=" * 60)

def main():
    """ä¸»å‡½æ•°"""
    # ä½¿ç”¨è½¬æ¢åçš„æ ‡æ³¨æ–‡ä»¶
    # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨æ‚¨ä¹‹å‰ä»£ç ç”Ÿæˆçš„ existing_videos_dataset.json
    # å¦‚æœæ‚¨æœ‰ä¸åŒçš„æ–‡ä»¶ï¼Œè¯·ä¿®æ”¹è¿™ä¸ªè·¯å¾„
    ANNOTATIONS_FILE = "/root/workspace/vqa_dataset_prepared/converted_annotations/existing_videos_dataset.json"
    OUTPUT_DIR = "/root/workspace/video_vqa_dataset"
    
    print("=" * 60)
    print("è§†é¢‘VQAæ•°æ®é›†ç”Ÿæˆå·¥å…·ï¼ˆè§†é¢‘ç²’åº¦ï¼Œåˆå¹¶åŠ¨ä½œï¼‰- å¢å¼ºå»é‡å’Œåˆå¹¶ç‰ˆ")
    print("=" * 60)
    print(f"ğŸ“ æ ‡æ³¨æ–‡ä»¶: {ANNOTATIONS_FILE}")
    print(f"ğŸ“¦ è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    print("=" * 60)
    print("ğŸ“‹ åŠŸèƒ½è¯´æ˜:")
    print("  - ä»è½¬æ¢åçš„æ ‡æ³¨æ–‡ä»¶ç”Ÿæˆè§†é¢‘ç²’åº¦çš„VQAæ•°æ®é›†")
    print("  - åˆå¹¶åŒä¸€è§†é¢‘çš„å¤šä¸ªåŠ¨ä½œä¸ºä¸€ä¸ªç»¼åˆç­”æ¡ˆ")
    print("  - æ¯ä¸ªåŠ¨ä½œéƒ½æœ‰ç‹¬ç«‹çš„å¼€å§‹å’Œç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰")
    print("  - ä½¿ç”¨åŒè¾¹é—­åˆæ ‡ç­¾<xxx>ç›®æ ‡å†…å®¹</xxx>")
    print("  - é€‚åº”è§†é¢‘ï¼Œæ¯ç§’1å¸§å¤„ç†")
    print("  - æŒ‰ç±»åˆ«80%è®­ç»ƒé›†ã€20%æµ‹è¯•é›†åˆ’åˆ†")
    print("  - åªä½¿ç”¨è§†é¢‘å­˜åœ¨çš„æ ‡æ³¨")
    print("  - å¤šåŠ¨ä½œç”¨åˆ†å·æˆ–andè¿æ¥")
    print("  - å¢å¼ºå»é‡åŠŸèƒ½ï¼Œé¿å…é‡å¤åŠ¨ä½œ")
    print("  - åˆå¹¶é‡å æˆ–ç›¸é‚»çš„ç›¸åŒåŠ¨ä½œ")
    print("=" * 60)
    
    # æ£€æŸ¥æ ‡æ³¨æ–‡ä»¶
    if not os.path.exists(ANNOTATIONS_FILE):
        logger.error(f"æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {ANNOTATIONS_FILE}")
        print(f"\nâŒ é”™è¯¯: æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {ANNOTATIONS_FILE}")
        print("è¯·å…ˆè¿è¡Œæ ‡ç­¾è½¬æ¢è„šæœ¬ç”Ÿæˆæ ‡æ³¨æ–‡ä»¶")
        return
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©º
    if os.path.getsize(ANNOTATIONS_FILE) == 0:
        logger.error(f"æ ‡æ³¨æ–‡ä»¶ä¸ºç©º: {ANNOTATIONS_FILE}")
        print(f"\nâŒ é”™è¯¯: æ ‡æ³¨æ–‡ä»¶ä¸ºç©º: {ANNOTATIONS_FILE}")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # åˆå§‹åŒ–æ•°æ®é›†æ„å»ºå™¨
    builder = VideoVQADatasetBuilder(
        annotations_file=ANNOTATIONS_FILE,
        output_dir=OUTPUT_DIR,
        train_ratio=0.8,
        merge_interval=1  # ç›¸é‚»1ç§’å†…çš„ç›¸åŒåŠ¨ä½œä¼šåˆå¹¶
    )
    
    # åŠ è½½æ‰€æœ‰æ ‡æ³¨
    all_annotations = builder.load_all_annotations()
    if not all_annotations:
        logger.error("æ²¡æœ‰æ‰¾åˆ°æ ‡æ³¨æ•°æ®")
        print("\nâŒ é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°æ ‡æ³¨æ•°æ®")
        print("è¯·æ£€æŸ¥æ ‡æ³¨æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®")
        return
    
    # æŒ‰è§†é¢‘åˆ†ç»„
    video_groups = builder.group_by_video(all_annotations)
    if not video_groups:
        logger.error("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è§†é¢‘æ ‡æ³¨")
        print("\nâŒ é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è§†é¢‘æ ‡æ³¨")
        print("è¯·ç¡®ä¿æ ‡æ³¨æ–‡ä»¶ä¸­åŒ…å«æœ‰æ•ˆçš„è§†é¢‘è·¯å¾„")
        return
    
    # å¤„ç†è§†é¢‘ç»„ï¼Œç”Ÿæˆè§†é¢‘ç²’åº¦çš„æ ·æœ¬
    video_samples = builder.process_video_groups(video_groups)
    if not video_samples:
        logger.error("æ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„è§†é¢‘æ ·æœ¬")
        print("\nâŒ é”™è¯¯: æ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„è§†é¢‘æ ·æœ¬")
        print("è¯·æ£€æŸ¥æ ‡æ³¨æ•°æ®æ˜¯å¦åŒ…å«æœ‰æ•ˆçš„æ—¶é—´èŒƒå›´å’Œæ ‡ç­¾")
        return
    
    # æŒ‰ç±»åˆ«åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    train_data, test_data = builder.split_by_category(video_samples)
    
    if not train_data and not test_data:
        logger.error("æ— æ³•åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†")
        print("\nâŒ é”™è¯¯: æ— æ³•åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†")
        return
    
    # ä¿å­˜æ•°æ®é›†
    output_path, stats = builder.save_dataset(train_data, test_data)
    
    # ç”Ÿæˆæ ·æœ¬è¾“å‡º
    builder.generate_sample_output(train_data, test_data, output_path)
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 60)
    print("ğŸ‰ æ•°æ®é›†ç”Ÿæˆå®Œæˆ")
    print("=" * 60)
    print(f"ğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
    print(f"  âœ… æ€»è§†é¢‘æ•°: {stats['dataset_info']['total_videos']}")
    print(f"  ğŸ“š è®­ç»ƒé›†: {stats['dataset_info']['train_videos']} ä¸ªè§†é¢‘")
    print(f"  ğŸ“Š æµ‹è¯•é›†: {stats['dataset_info']['test_videos']} ä¸ªè§†é¢‘")
    print(f"  ğŸ¯ è®­ç»ƒæ¯”ä¾‹: {stats['dataset_info']['train_ratio'] * 100}%")
    print(f"  ğŸ”„ åˆå¹¶é—´éš”: {stats['dataset_info']['merge_interval']} ç§’")
    
    print(f"\nğŸ“¹ è§†é¢‘ç»Ÿè®¡:")
    print(f"  ğŸ¬ å”¯ä¸€è§†é¢‘æ•°: {stats['video_info']['unique_videos_total']}")
    print(f"  ğŸ¯ è®­ç»ƒé›†è§†é¢‘: {stats['video_info']['unique_videos_train']}")
    print(f"  ğŸ“Š æµ‹è¯•é›†è§†é¢‘: {stats['video_info']['unique_videos_test']}")
    print(f"  â±ï¸  å¹³å‡è§†é¢‘æ—¶é•¿: {stats['video_info']['avg_video_duration_train']:.1f}ç§’ (è®­ç»ƒé›†)")
    
    print(f"\nğŸ·ï¸  ç±»åˆ«ç»Ÿè®¡:")
    print(f"  ğŸ“‚ æ€»ç±»åˆ«æ•°: {stats['category_info']['total_categories']}")
    print(f"  ğŸ¯ è®­ç»ƒé›†å‰5ä¸ªç±»åˆ«:")
    for i, (category, count) in enumerate(list(stats['category_info']['train_categories'].items())[:5], 1):
        print(f"     {i}. {category}: {count} ä¸ªè§†é¢‘")
    
    print(f"\nğŸ¬ åŠ¨ä½œç»Ÿè®¡:")
    print(f"  ğŸ“ˆ è®­ç»ƒé›†å¹³å‡åŠ¨ä½œæ•°/è§†é¢‘: {stats['action_info']['avg_actions_per_video_train']:.2f}")
    print(f"  ğŸ“ˆ æµ‹è¯•é›†å¹³å‡åŠ¨ä½œæ•°/è§†é¢‘: {stats['action_info']['avg_actions_per_video_test']:.2f}")
    print(f"  ğŸ“Š è®­ç»ƒé›†æœ€å¤§åŠ¨ä½œæ•°: {stats['action_info']['max_actions_train']}")
    print(f"  ğŸ“Š æµ‹è¯•é›†æœ€å¤§åŠ¨ä½œæ•°: {stats['action_info']['max_actions_test']}")
    
    print(f"\nğŸ”„ åˆå¹¶ç»Ÿè®¡:")
    print(f"  ğŸ“‰ è®­ç»ƒé›†åˆå¹¶åŠ¨ä½œæ•°: {stats['merge_info']['total_merged_actions_train']}")
    print(f"  ğŸ“‰ æµ‹è¯•é›†åˆå¹¶åŠ¨ä½œæ•°: {stats['merge_info']['total_merged_actions_test']}")
    print(f"  ğŸ“ˆ è®­ç»ƒé›†åŸå§‹æ ‡æ³¨æ•°: {stats['merge_info']['total_original_actions_train']}")
    print(f"  ğŸ“ˆ æµ‹è¯•é›†åŸå§‹æ ‡æ³¨æ•°: {stats['merge_info']['total_original_actions_test']}")
    print(f"  ğŸ“Š è®­ç»ƒé›†å‹ç¼©ç‡: {stats['merge_info']['compression_rate_train']:.2%}")
    print(f"  ğŸ“Š æµ‹è¯•é›†å‹ç¼©ç‡: {stats['merge_info']['compression_rate_test']:.2%}")
    
    print(f"\nğŸ“ è¾“å‡ºç›®å½•: {output_path}")
    print("ç”Ÿæˆçš„æ–‡ä»¶:")
    for file in os.listdir(output_path):
        file_path = os.path.join(output_path, file)
        if os.path.isfile(file_path):
            size_kb = os.path.getsize(file_path) / 1024
            print(f"  ğŸ“„ {file} ({size_kb:.1f} KB)")
    
    print(f"\nğŸš€ ä¸‹ä¸€æ­¥å»ºè®®:")
    print("1. æ£€æŸ¥ç”Ÿæˆçš„æ•°æ®é›†æ ¼å¼æ˜¯å¦æ­£ç¡®")
    print("2. æŸ¥çœ‹samples.jsonæ–‡ä»¶äº†è§£æ•°æ®æ ¼å¼")
    print("3. åœ¨å¾®è°ƒè„šæœ¬ä¸­ï¼Œä½¿ç”¨è§†é¢‘è·¯å¾„å’Œå¼€å§‹ç»“æŸæ—¶é—´è¿›è¡ŒæŠ½å¸§")
    print("4. ä½¿ç”¨è®­ç»ƒé›†è®­ç»ƒè§†é¢‘VQAæ¨¡å‹")
    print("5. ä½¿ç”¨æµ‹è¯•é›†è¯„ä¼°æ¨¡å‹æ€§èƒ½")
    
    print("=" * 60)
    
    # æ˜¾ç¤ºç‰¹æ®Šæ ‡è®°ä½¿ç”¨è¯´æ˜
    print("\nğŸ”¤ ç‰¹æ®Šæ ‡è®°è¯´æ˜:")
    print("  <start_time>èµ·å§‹æ—¶é—´</start_time>: åŠ¨ä½œèµ·å§‹æ—¶é—´ï¼ˆç§’ï¼‰")
    print("  <end_time>ç»“æŸæ—¶é—´</end_time>: åŠ¨ä½œç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰")
    print("  <driving_maneuver>åŠ¨ä½œæ ‡ç­¾</driving_maneuver>: é©¾é©¶åŠ¨ä½œæ ‡ç­¾")
    print("\nğŸ“ ç¤ºä¾‹é—®é¢˜-ç­”æ¡ˆå¯¹:")
    if train_data:
        sample = train_data[0]
        print(f"\n  é—®é¢˜: {sample.get('question', '')}")
        print(f"  ç­”æ¡ˆ: {sample.get('answer', '')}")
        
        # æ˜¾ç¤ºå¤šåŠ¨ä½œç¤ºä¾‹
        if sample.get('num_actions', 0) > 1:
            print(f"\n  ğŸ”„ å¤šåŠ¨ä½œç¤ºä¾‹è§£æ:")
            annotations = sample.get('annotations', [])
            for i, ann in enumerate(annotations, 1):
                label = ann.get('label_en', 'unknown')
                time_range = ann.get('time_range_frames', [0, 0])
                merged_count = ann.get('merged_count', 0)
                if merged_count > 0:
                    print(f"    åŠ¨ä½œ{i}: {label} ({time_range[0]}-{time_range[1]}ç§’, åˆå¹¶äº†{merged_count}ä¸ªæ ‡æ³¨)")
                else:
                    print(f"    åŠ¨ä½œ{i}: {label} ({time_range[0]}-{time_range[1]}ç§’)")
    
    print("=" * 60)

if __name__ == "__main__":
    main()