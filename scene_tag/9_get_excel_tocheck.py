#!/usr/bin/env python3
"""
ç”Ÿæˆè§†é¢‘éªŒè¯è¡¨æ ¼
ç”¨äºäººå·¥æ£€æŸ¥åˆ‡ç‰‡è§†é¢‘å’Œæ¨¡å‹é¢„æµ‹æ ‡ç­¾æ˜¯å¦åŒ¹é…
"""

import json
import pandas as pd
from pathlib import Path

def generate_validation_table(predict_jsonl_path, dataset_json_path, output_csv_path="video_validation.csv"):
    """ç”Ÿæˆè§†é¢‘éªŒè¯è¡¨æ ¼"""
    
    # è¯»å–æ•°æ®
    with open(dataset_json_path, 'r') as f:
        dataset = json.load(f)
    
    predictions = []
    with open(predict_jsonl_path, 'r') as f:
        for line in f:
            predictions.append(json.loads(line.strip()))
    
    # ç”ŸæˆéªŒè¯æ•°æ®
    validation_data = []
    
    for i, (data, pred) in enumerate(zip(dataset, predictions)):
        # è·å–è§†é¢‘è·¯å¾„
        video_path = data['videos'][0] if 'videos' in data and data['videos'] else ''
        
        # è·å–é¢„æµ‹ç»“æœ
        predict_text = pred.get('predict', '')
        
        # æå–æ ‡ç­¾
        import re
        labels = re.findall(r'<driving_maneuver>(.*?)</driving_maneuver>', predict_text)
        
        if labels:
            for label in labels:
                validation_data.append({
                    'è§†é¢‘è·¯å¾„': video_path,
                    'é¢„æµ‹æ ‡ç­¾': label,
                    'å®Œæ•´é¢„æµ‹': predict_text[:100] + '...' if len(predict_text) > 100 else predict_text,
                    'åºå·': i + 1
                })
        else:
            validation_data.append({
                'è§†é¢‘è·¯å¾„': video_path,
                'é¢„æµ‹æ ‡ç­¾': 'æ— æ ‡ç­¾',
                'å®Œæ•´é¢„æµ‹': predict_text[:100] + '...' if len(predict_text) > 100 else predict_text,
                'åºå·': i + 1
            })
    
    # ä¿å­˜ä¸ºCSV
    df = pd.DataFrame(validation_data)
    df.to_csv(output_csv_path, index=False, encoding='utf-8-sig')
    
    print(f"âœ… éªŒè¯è¡¨æ ¼å·²ç”Ÿæˆ: {output_csv_path}")
    print(f"  æ•°æ®é›†æ ·æœ¬æ•°: {len(dataset)}")
    print(f"  é¢„æµ‹æ ·æœ¬æ•°: {len(predictions)}")
    print(f"  éªŒè¯æ¡ç›®æ•°: {len(df)}")
    
    # æ˜¾ç¤ºæ ‡ç­¾ç»Ÿè®¡
    if not df.empty:
        print(f"\næ ‡ç­¾ç»Ÿè®¡:")
        label_counts = df['é¢„æµ‹æ ‡ç­¾'].value_counts()
        for label, count in label_counts.items():
            print(f"  {label}: {count}")
    
    return output_csv_path

if __name__ == "__main__":
    # è®¾ç½®ä½ çš„æ–‡ä»¶è·¯å¾„
    predict_file = "/root/workspace/LLaMA-Factory/infer_results/12tags_Qwen3-VL-4B_segment_upstream_1epoch_digged.jsonl"  # æ›¿æ¢ä¸ºä½ çš„é¢„æµ‹æ–‡ä»¶è·¯å¾„
    dataset_file = "/mnt/pfs/houhaotian/segemnt_inference_dataset.json"  # æ•°æ®é›†æ–‡ä»¶è·¯å¾„
    output_file = "/root/workspace/LLaMA-Factory/dig_result/video_validation.csv"  # è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯è‡ªå®šä¹‰ï¼‰
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    for path, desc in [(predict_file, "é¢„æµ‹ç»“æœæ–‡ä»¶"), (dataset_file, "æ•°æ®é›†æ–‡ä»¶")]:
        if not Path(path).exists():
            print(f"âŒ é”™è¯¯: {desc}ä¸å­˜åœ¨: {path}")
            exit(1)
    
    # ç”ŸæˆéªŒè¯è¡¨æ ¼
    csv_path = generate_validation_table(predict_file, dataset_file, output_file)
    
    print(f"\nğŸ“‹ ä½¿ç”¨è¯´æ˜:")
    print(f"1. è¡¨æ ¼å·²ä¿å­˜åˆ°: {csv_path}")
    print(f"2. ç”¨Excelæˆ–æ–‡æœ¬ç¼–è¾‘å™¨æ‰“å¼€æŸ¥çœ‹")
    print(f"3. æ ¹æ®'è§†é¢‘è·¯å¾„'æ‰¾åˆ°è§†é¢‘æ–‡ä»¶ï¼Œæ’­æ”¾æŸ¥çœ‹")
    print(f"4. å¯¹ç…§'é¢„æµ‹æ ‡ç­¾'åˆ¤æ–­æ¨¡å‹é¢„æµ‹æ˜¯å¦æ­£ç¡®")
    print(f"5. å¯ä»¥æŒ‰'é¢„æµ‹æ ‡ç­¾'æ’åºï¼Œæ‰¹é‡æ£€æŸ¥åŒç±»è§†é¢‘")